{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4elnnebYFymJ"
   },
   "source": [
    "<center><h1>EMG-based Estimations of Joints Angles and Torquse Using Long Short-Term Memory Network</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUmXlf9RFyTC"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Move back to the main folder, Make sure to run this cell only at the start\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "x6ncuNJLwbop",
    "outputId": "62eebb2c-0137-42e8-82cf-4e40e5883609"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi'] = 100\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "plt.figure(dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYSY1R3zMlcq"
   },
   "source": [
    "## define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rH9NNXjGMkwt"
   },
   "outputs": [],
   "source": [
    "features_num=88 #Number of features in the model\n",
    "out_num=9 # Number of outputs\n",
    "time_steps=50 # time step for training LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjRkKRTaEQEH"
   },
   "source": [
    "## Create Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p084FkpsMC09"
   },
   "source": [
    "### getting labels function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2xpYPhzwyTZf"
   },
   "outputs": [],
   "source": [
    "def get_labels():\n",
    "    \"\"\"\n",
    "    Used to get Output labels as a numpy array. Labels are retrived from Subject 1 dataset\n",
    "    Labels are ['knee_angle_r', 'ankle_angle_r', 'knee_angle_l', 'ankle_angle_l',\n",
    "            'knee_angle_r_moment', 'knee_angle_l_moment',\n",
    "            'ankle_angle_r_moment', 'ankle_angle_l_moment']\n",
    "    Returns\n",
    "    -------\n",
    "    list contains all output labels\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    output_label =[\"Right Knee Angle\", \"Left Knee Angle\", \"Right Hip Angle\",\n",
    "                \"Left Hip Angle\", \"Right Knee Torque\", \"Left Knee Torque\", \"Right Hip Torque\", \"Left Hip Torque\", \"Shank Gyro Y IMU\"]\n",
    "    return output_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI-LDwDtR1ck"
   },
   "source": [
    "### dataset pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z1uTp4ueQP15"
   },
   "outputs": [],
   "source": [
    "def get_dataset(subject_no):\n",
    "    \"\"\"\n",
    "    This function is used to retrive the dataset for selected subject. Dataset\n",
    "    will and last 8 columns contains the output. All columns are labeled.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subject_no : string\n",
    "    Subject number in format XX.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataset\n",
    "    Subject number \"subject_no\" dataset without time column\n",
    "    \n",
    "    \"\"\"\n",
    "    subject_no = \"01\"\n",
    "    dataset = pd.read_csv('Subject' + subject_no + '_dataset_20200207_50ms.csv',header=0)\n",
    "    return dataset.drop(columns=\"Time\").dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WjNNNSeBQYdN"
   },
   "outputs": [],
   "source": [
    "def get_scaler(ndarray, features_range=(-1,1)):\n",
    "    \"\"\"\n",
    "    This function is used for creating scalers for scalling the features using\n",
    "    sklearn.preprocessing.MinMaxScaler function.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ndarray : numpy arrayor pandas dataset\n",
    "    DESCRIPTION.\n",
    "    scale_range : Tuple, optional\n",
    "    Scaling range (Min,Max). The default is (-1,1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scaler : MinMaxscaler\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler(feature_range=features_range)\n",
    "    scaler.fit(ndarray)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "EXe_fcDnQhNh"
   },
   "outputs": [],
   "source": [
    "def scale_data(dataset, features_range=(-1,1), outputs_range=None):\n",
    "    \"\"\"\n",
    "    Scale input/output using MinMaxScaler. inputs are scaled in range (-1,1)\n",
    "    and outputs scaled in general model case only using range of (0,1)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : numpy array or pandas\n",
    "      Dataset to be scaled.\n",
    "    features_range : tuple\n",
    "      The scaler range for input features. Default (-1,-1)\n",
    "    outputs_range : tuple or None\n",
    "      Scale all outputs in range the desired range. If None, no scaling will\n",
    "      be performed. Default value is None.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scaled_dataset : numpy array\n",
    "      a numpy array contains the scaled dataset.\n",
    "    output_scaler : MinMaxscaler\n",
    "      Output values scaler. Optional if Outpus_range is not None\n",
    "\n",
    "    \"\"\"\n",
    "    dataset_values = dataset.values.astype(\"float32\")\n",
    "    input_scaler = get_scaler(dataset_values[:,:-out_num]) #get scaler for input features\n",
    "    input_dataset = input_scaler.transform(dataset_values[:,:-out_num]) #scale input features\n",
    "    if outputs_range==None:\n",
    "        output_dataset = dataset_values[:,-out_num:]\n",
    "        scaled_dataset = np.concatenate((dataset_values[:,:-out_num],output_dataset), axis=1)\n",
    "        return scaled_dataset\n",
    "    else:\n",
    "        output_scaler = get_scaler(dataset_values[:,-out_num:], scale_range=outputs_range)\n",
    "        output_dataset = output_scaler.transform(dataset_values[:,-out_num:])\n",
    "        scaled_dataset = np.concatenate((dataset_values[:,:-out_num],output_dataset), axis=1)\n",
    "        return scaled_dataset, output_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "93Nz8PMGwcXF"
   },
   "outputs": [],
   "source": [
    "def create_inout_sequences(data_set):\n",
    "    \"\"\"\n",
    "    Create the input and output pairs sequances for the model\n",
    "\n",
    "      Parameters\n",
    "    ----------\n",
    "    input_data : numpy array\n",
    "        Subject dataset pair (inputs & Ooutputs).\n",
    "    features : int\n",
    "        Number of features in our model. default is 112\n",
    "    out_num : int\n",
    "        Number of outputs for the model to predict. outputs are arranged same way the get_label() function output.\n",
    "        default value is 8\n",
    "    time_steps : int\n",
    "        Time step for training LSTM model. default value is 50\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : numpy array\n",
    "        Numpy array with the shape (len(data_set)-time_step ,time_steps, features) contains the features.\n",
    "    outputs : numpy array\n",
    "        Numpy array with the shape (len(data_set)-time_step ,time_steps, out_num) contains all ouputs corrsponding to the features\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    outputs =  []\n",
    "    L = len(data_set)\n",
    "    for i in range(L-time_steps):\n",
    "        inputs = data_set[i:i+time_steps,:features_num]\n",
    "        labels = data_set[i:i+time_steps,-out_num:]\n",
    "        features.append(inputs)\n",
    "        outputs.append(labels)\n",
    "    features = np.array(features)\n",
    "    outputs = np.array(outputs)\n",
    "    return features,outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hbmiN0d1GjVd"
   },
   "source": [
    "## Create a function that will process all the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AX8LYlXny_MG"
   },
   "outputs": [],
   "source": [
    "def in_out_process(subject, mod=\"training_set\", test_val_size=0.4, features_range=(-1,1), outputs_range=None):\n",
    "    \"\"\"\n",
    "    This function will process the dataset and give us the training, validation and test sets without shuffeling \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    subject: an \"XX\" string format.\n",
    "    mod: a string that tells the function about the goal of the recieved data set, is it for training or testing. Either \"training_set\" or \"test_set\".\n",
    "    test_val_size: float between [0,1), show the percentage of the validation and test sets from the total data set.\n",
    "      data will be as follow:\n",
    "      from 0 to (1-test_val_size)% for training\n",
    "      from (1-test_val_size)% to (1-test_val_size/2) for validation\n",
    "      from (1-test_val_size/2)% till the end of the data set for testing\n",
    "    features_range : tuple\n",
    "      The scaler range for input features. Default (-1,-1)\n",
    "    outputs_range : tuple or None\n",
    "      Scale all outputs in range the desired range. If None, no scaling will\n",
    "      be performed. Default value is None.\n",
    "\n",
    "    Returns:\n",
    "    X_train, X_val, y_train, y_val arrays as float32 tensors if mod is set for \"training_set\"\n",
    "    X_test, y_test if mod is set for \"test_set\"\n",
    "    \"\"\"\n",
    "    # in case of training\n",
    "    if mod==\"training_set\":\n",
    "        # Load the dataset\n",
    "        dataset = get_dataset(subject)\n",
    "        # Scale the dataset\n",
    "        scaled_dataset = scale_data(dataset, features_range=features_range\n",
    "                                   , outputs_range=None)\n",
    "        # get features and outputs\n",
    "        features, outputs = create_inout_sequences(scaled_dataset)\n",
    "        # get training set\n",
    "        X_train, X_test_val, y_train, y_test_val = train_test_split(features, outputs,\n",
    "                                                          test_size = test_val_size,\n",
    "                                                          random_state=None, shuffle=False)\n",
    "        # get validation\n",
    "        X_val, _, y_val, _ = train_test_split(features, outputs,\n",
    "                                              test_size = test_val_size/2,\n",
    "                                              random_state=None, shuffle=False)\n",
    "\n",
    "        print(\"Dataset_size: %2d, train_size: %2d, test_size: %2d\" %(len(features),\n",
    "                                                                    len(X_train),\n",
    "                                                                    len(X_val)))\n",
    "\n",
    "        return tf.constant(X_train,tf.float32), tf.constant(X_val,tf.float32), tf.constant(y_train,tf.float32), tf.constant(y_val,tf.float32)\n",
    "    # in case of testing\n",
    "    elif mod ==\"test_set\":\n",
    "        # Load the dataset\n",
    "        dataset = get_dataset(subject)\n",
    "        # Scale the dataset\n",
    "        scaled_dataset = scale_data(dataset)\n",
    "        # get test set starting point\n",
    "        test_len = int((1-test_val_size/2)*len(scaled_dataset))\n",
    "        # get test set\n",
    "        X_test = scaled_dataset[test_len: ,:-out_num]\n",
    "        y_test = scaled_dataset[test_len:,-out_num:]\n",
    "        return X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DVSvg1kHv2V"
   },
   "source": [
    "## Model creation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01u3329ASu1Q"
   },
   "source": [
    "### define a function to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9cYR4hoA3Y_X"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    keras.backend.clear_session() # Make sure we do not have any model in the notebook\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(4, return_sequences=True, input_shape=(time_steps, features_num),\n",
    "                              dropout=0.3), name=\"input_layer\"))\n",
    "    model.add(keras.layers.Bidirectional(keras.layers.LSTM(4, return_sequences=True,\n",
    "                              dropout=0.3), name=\"2nd_layer\"))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Dense(out_num), name=\"output_layer\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHFt2RYOSfSw"
   },
   "source": [
    "### Model Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tQu9qE1L-0IW"
   },
   "outputs": [],
   "source": [
    "def col_arranger(df):\n",
    "    \"\"\"\n",
    "    Arrange columns to match the paper\n",
    "    \"\"\"\n",
    "    DF = df[['Right Knee Angle', 'Left Knee Angle', 'Right Hip Angle',\n",
    "                'Left Hip Angle', 'Right Knee Torque', 'Left Knee Torque', 'Right Hip Torque', 'Left Hip Torque', 'Shank Gyro Y IMU']]\n",
    "    return DF\n",
    "\n",
    "def rmse_cal(Y_pred,Y):\n",
    "    \"\"\"\n",
    "    This function will calculate RMSE values\n",
    "    \"\"\"\n",
    "    size = Y_pred.shape[0]\n",
    "    rmse_value = np.sqrt(np.sum((Y_pred - Y)**2)/size)\n",
    "    return rmse_value\n",
    "\n",
    "def R2_cal(Y_pred,Y):\n",
    "    \"\"\"\n",
    "    This function will calculate R2 scores\n",
    "    \"\"\"\n",
    "    size = Y_pred.shape[0]\n",
    "    R2_value = 1 - np.sum((Y_pred - Y)**2)/np.sum(Y**2)\n",
    "    return R2_value\n",
    "        \n",
    "#Get the predicted values from the test dataset\n",
    "def get_prediction(inputs, model):\n",
    "    \"\"\"\n",
    "    get the predictions from inputs\n",
    "    inputs came in shape (length of the test set, features_num)\n",
    "    \"\"\"\n",
    "    m = len(inputs)\n",
    "    for i in range(0,m-50,50):\n",
    "        X = inputs[i:i+50,:]\n",
    "        len(X)\n",
    "        print(len(X))\n",
    "        X = np.reshape(X,(1,50,88))\n",
    "        if i == 0:\n",
    "            Y_preds = model.predict(X) \n",
    "        else:\n",
    "            y_pred = model.predict(X)\n",
    "            Y_preds = np.concatenate((Y_preds, y_pred))\n",
    "    return np.reshape(Y_preds,(-1,out_num))\n",
    "\n",
    "def evaluation(Y, Y_pred, Folder, labels=get_labels()):   \n",
    "    \"\"\"\n",
    "    Evaluate the model and plot the results\n",
    "    \"\"\" \n",
    "    time = [i*0.05 for i in range(len(Y_pred))]\n",
    "    frame_size=len(time)\n",
    "    r2_score = []\n",
    "    RMSE_score = []\n",
    "    for col in range(out_num):\n",
    "        rmse = np.round(rmse_cal(Y[:frame_size, col], Y_pred[:frame_size, col]),2)\n",
    "        R2 = np.round(R2_cal(Y[:frame_size, col],Y_pred[:frame_size, col]),4)\n",
    "        RMSE_score.append(rmse)\n",
    "        r2_score.append(R2)\n",
    "        if col == 0 or col == 1 or col == 2 or col == 3:\n",
    "            y_label = 'Degree'\n",
    "            unit = '\\xB0'\n",
    "        else:\n",
    "            y_label = 'Nm'\n",
    "            unit = ' Nm'\n",
    "        print('R2_score' + f'({labels[col]}) =', R2)\n",
    "        print('RMSE' + f'({labels[col]}) = {rmse}' + unit)\n",
    "        plt.plot(time[:frame_size], Y[:frame_size, col], 'r')\n",
    "        plt.plot(time[:frame_size], Y_pred[:frame_size, col], 'b--')\n",
    "        plt.xlabel('Time [s]', fontsize=14)\n",
    "        plt.xlim((0,30))\n",
    "        plt.ylabel(y_label, fontsize=14)\n",
    "        plt.xticks(fontsize=11)\n",
    "        plt.yticks(fontsize=11)\n",
    "        plt.title(labels[col], fontsize=\"xx-large\")\n",
    "        plt.savefig(Folder + '/' + f'{labels[col]}.pdf')\n",
    "        plt.show()\n",
    "\n",
    "    return r2_score, RMSE_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JSU9w6R43cs-"
   },
   "source": [
    "## Train and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vTgGLTcGDA2u"
   },
   "outputs": [],
   "source": [
    "def train_eval(subject=1, lr=0.001, test_val_size=0.4,\n",
    "               load_best=False, eval_only=False, features_range=(-1, 1)):\n",
    "    \"\"\"\n",
    "    This function will train and evaluated the model\n",
    "    load_best: to load trainable saved model\n",
    "    eval_only: to skip training process and evaluate the model only, if it set to True, load_best will be True\n",
    "    \"\"\"\n",
    " \n",
    "    global model_path # Create model folder and path and make them global\n",
    "    #Folder = \"S\" + subject\n",
    "    #if not os.path.exists(Folder): #if folder doesn't exist, create one\n",
    "        #os.makedirs(Folder)\n",
    "    model_path = r\"C:/Users/ibra5/Desktop/LSTM/Model Output_05/model.hdf5\" # Model path and name\n",
    "\n",
    "    output_label = get_labels() #import the labels\n",
    "    if not eval_only: #load dataset for training the model\n",
    "        X_train, X_val, y_train, y_val = in_out_process(subject, mod=\"training_set\",\n",
    "                                                        test_val_size=test_val_size, \n",
    "                                                        features_range=features_range)\n",
    "\n",
    "    model = create_model() # Create the model\n",
    "    try:\n",
    "        if load_best or eval_only: #load best model if we will evaluate the model only our we want to start training from pre-trained model\n",
    "            if os.path.exists(model_path): # make sure model exist\n",
    "                model.load_weights(model_path)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "          # Train the model\n",
    "        if not eval_only:\n",
    "            model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr), loss=\"MSE\") # Create model Compiler\n",
    "            # Define Check points for saving best model while training\n",
    "            model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint( \n",
    "            filepath = model_path,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True)\n",
    "\n",
    "            training = model.fit(x=X_train, y=y_train, batch_size=64, epochs=6500,\n",
    "                              validation_data=(X_val,y_val), \n",
    "                              callbacks=[model_checkpoint_callback])\n",
    "      \n",
    "            # Plot learning curve after the end of training\n",
    "            print(\"\\ntrain end\\n\\n Plotting Learning Curve\")\n",
    "            plt.plot(training.history[\"loss\"][100:])\n",
    "            plt.plot(training.history[\"val_loss\"][100:])\n",
    "            plt.title(\"Model loss\")\n",
    "            plt.ylabel(\"loss\")\n",
    "            plt.xlabel(\"epoch\")\n",
    "            plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "            plt.show()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTrain manually stopped\\n\\n\")\n",
    "\n",
    "    #Evaluate the model\n",
    "    # Get test set\n",
    "    X_test, y_test = in_out_process(subject, mod=\"test_set\", test_val_size=test_val_size, features_range=(-1,1))\n",
    "    # Get predictions\n",
    "    y_test_preds = get_prediction(X_test, model)\n",
    "    # Get R2 and RMSE results and plot measurements against predictions\n",
    "    r2_score, RMSE_score = evaluation(y_test, y_test_preds, Folder=r\"C:/Users/ibra5/Desktop/LSTM/Model Output_05\", labels=output_label)\n",
    "\n",
    "    # Return results as a pandas dataframe\n",
    "    r2_score = pd.DataFrame(data=np.array(r2_score,ndmin=2), columns=output_label)\n",
    "    r2_score.index = {\"S\" + subject}\n",
    "\n",
    "    RMSE_score = pd.DataFrame(data=np.array(RMSE_score, ndmin=2), columns=output_label)\n",
    "    RMSE_score.index = {\"S\" + subject}\n",
    "    # arrange columns and get the output\n",
    "    return col_arranger(r2_score), col_arranger(RMSE_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bKMg_ww4U37D"
   },
   "source": [
    "## Train model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset_size: 2809, train_size: 1685, test_size: 2247\n",
      "Epoch 1/6500\n",
      "27/27 [==============================] - 11s 138ms/step - loss: 548.2346 - val_loss: 553.1248\n",
      "Epoch 2/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 541.0104 - val_loss: 543.4117\n",
      "Epoch 3/6500\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 531.5760 - val_loss: 532.4789\n",
      "Epoch 4/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 520.2256 - val_loss: 521.0638\n",
      "Epoch 5/6500\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 508.5036 - val_loss: 509.9325\n",
      "Epoch 6/6500\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 497.3471 - val_loss: 499.2501\n",
      "Epoch 7/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 486.9511 - val_loss: 489.3055\n",
      "Epoch 8/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 477.3719 - val_loss: 480.1414\n",
      "Epoch 9/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 468.4174 - val_loss: 471.0584\n",
      "Epoch 10/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 459.6042 - val_loss: 462.9841\n",
      "Epoch 11/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 451.8770 - val_loss: 455.6888\n",
      "Epoch 12/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 444.7806 - val_loss: 448.8561\n",
      "Epoch 13/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 438.0958 - val_loss: 442.4007\n",
      "Epoch 14/6500\n",
      "27/27 [==============================] - 2s 55ms/step - loss: 431.7581 - val_loss: 436.2466\n",
      "Epoch 15/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 425.7054 - val_loss: 430.3703\n",
      "Epoch 16/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 419.9359 - val_loss: 424.7373\n",
      "Epoch 17/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 414.3913 - val_loss: 419.3346\n",
      "Epoch 18/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 409.0692 - val_loss: 414.1285\n",
      "Epoch 19/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 403.9481 - val_loss: 409.1171\n",
      "Epoch 20/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 399.0234 - val_loss: 404.2799\n",
      "Epoch 21/6500\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 394.2417 - val_loss: 399.6171\n",
      "Epoch 22/6500\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 389.6343 - val_loss: 395.1102\n",
      "Epoch 23/6500\n",
      "27/27 [==============================] - 2s 70ms/step - loss: 385.2028 - val_loss: 390.7524\n",
      "Epoch 24/6500\n",
      "27/27 [==============================] - 2s 86ms/step - loss: 380.8987 - val_loss: 386.5421\n",
      "Epoch 25/6500\n",
      "27/27 [==============================] - 2s 78ms/step - loss: 376.7462 - val_loss: 382.4678\n",
      "Epoch 26/6500\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 372.7334 - val_loss: 378.5260\n",
      "Epoch 27/6500\n",
      "27/27 [==============================] - 2s 85ms/step - loss: 368.8496 - val_loss: 374.7131\n",
      "Epoch 28/6500\n",
      "27/27 [==============================] - 2s 69ms/step - loss: 365.0959 - val_loss: 371.0191\n",
      "Epoch 29/6500\n",
      "27/27 [==============================] - 3s 93ms/step - loss: 361.4422 - val_loss: 367.4429\n",
      "Epoch 30/6500\n",
      "27/27 [==============================] - 2s 69ms/step - loss: 357.9251 - val_loss: 363.9772\n",
      "Epoch 31/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 354.5054 - val_loss: 360.6240\n",
      "Epoch 32/6500\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 351.2056 - val_loss: 357.3752\n",
      "Epoch 33/6500\n",
      "27/27 [==============================] - 2s 91ms/step - loss: 348.0043 - val_loss: 354.2254\n",
      "Epoch 34/6500\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 344.8905 - val_loss: 351.1767\n",
      "Epoch 35/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 341.8941 - val_loss: 348.2196\n",
      "Epoch 36/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 338.9879 - val_loss: 345.3556\n",
      "Epoch 37/6500\n",
      "27/27 [==============================] - 2s 73ms/step - loss: 336.1692 - val_loss: 342.5878\n",
      "Epoch 38/6500\n",
      "27/27 [==============================] - 2s 84ms/step - loss: 333.4304 - val_loss: 339.9071\n",
      "Epoch 39/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 330.7930 - val_loss: 337.3079\n",
      "Epoch 40/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 328.2286 - val_loss: 334.7806\n",
      "Epoch 41/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 325.7474 - val_loss: 332.3361\n",
      "Epoch 42/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 323.3399 - val_loss: 329.9707\n",
      "Epoch 43/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 321.0159 - val_loss: 327.6798\n",
      "Epoch 44/6500\n",
      "27/27 [==============================] - 3s 109ms/step - loss: 318.7600 - val_loss: 325.4640\n",
      "Epoch 45/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 316.5823 - val_loss: 323.3127\n",
      "Epoch 46/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 314.4566 - val_loss: 321.2344\n",
      "Epoch 47/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 312.4307 - val_loss: 319.2165\n",
      "Epoch 48/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 310.4478 - val_loss: 317.2657\n",
      "Epoch 49/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 308.5320 - val_loss: 315.3754\n",
      "Epoch 50/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 306.6808 - val_loss: 313.5501\n",
      "Epoch 51/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 304.8886 - val_loss: 311.7844\n",
      "Epoch 52/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 303.1579 - val_loss: 310.0761\n",
      "Epoch 53/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 301.4820 - val_loss: 308.4268\n",
      "Epoch 54/6500\n",
      "27/27 [==============================] - 2s 73ms/step - loss: 299.8683 - val_loss: 306.8261\n",
      "Epoch 55/6500\n",
      "27/27 [==============================] - 2s 82ms/step - loss: 298.3055 - val_loss: 305.2801\n",
      "Epoch 56/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 296.7879 - val_loss: 303.7825\n",
      "Epoch 57/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 295.3120 - val_loss: 302.3351\n",
      "Epoch 58/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 293.8985 - val_loss: 300.9372\n",
      "Epoch 59/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 292.5328 - val_loss: 299.5841\n",
      "Epoch 60/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 291.2108 - val_loss: 298.2766\n",
      "Epoch 61/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 289.9308 - val_loss: 297.0194\n",
      "Epoch 62/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 288.7031 - val_loss: 295.8013\n",
      "Epoch 63/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 287.5181 - val_loss: 294.6252\n",
      "Epoch 64/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 286.3733 - val_loss: 293.4898\n",
      "Epoch 65/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 285.2646 - val_loss: 292.3942\n",
      "Epoch 66/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 284.1953 - val_loss: 291.3364\n",
      "Epoch 67/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 283.1626 - val_loss: 290.3162\n",
      "Epoch 68/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 282.1694 - val_loss: 289.3342\n",
      "Epoch 69/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 281.2145 - val_loss: 288.3872\n",
      "Epoch 70/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 280.2909 - val_loss: 287.4726\n",
      "Epoch 71/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 279.4069 - val_loss: 286.5905\n",
      "Epoch 72/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 278.5537 - val_loss: 285.7405\n",
      "Epoch 73/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 277.7274 - val_loss: 284.9229\n",
      "Epoch 74/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 276.9374 - val_loss: 284.1346\n",
      "Epoch 75/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 276.1770 - val_loss: 283.3766\n",
      "Epoch 76/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 275.4401 - val_loss: 282.6518\n",
      "Epoch 77/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 57ms/step - loss: 274.7387 - val_loss: 281.9506\n",
      "Epoch 78/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 274.0560 - val_loss: 281.2761\n",
      "Epoch 79/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 273.4144 - val_loss: 280.6283\n",
      "Epoch 80/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 272.7827 - val_loss: 280.0065\n",
      "Epoch 81/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 272.1909 - val_loss: 279.4105\n",
      "Epoch 82/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 271.6142 - val_loss: 278.8353\n",
      "Epoch 83/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 271.0641 - val_loss: 278.2866\n",
      "Epoch 84/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 270.5405 - val_loss: 277.7546\n",
      "Epoch 85/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 270.0265 - val_loss: 277.2472\n",
      "Epoch 86/6500\n",
      "27/27 [==============================] - 2s 88ms/step - loss: 269.5367 - val_loss: 276.7586\n",
      "Epoch 87/6500\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 269.0736 - val_loss: 276.2928\n",
      "Epoch 88/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 268.6230 - val_loss: 275.8445\n",
      "Epoch 89/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 268.2024 - val_loss: 275.4153\n",
      "Epoch 90/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 267.7872 - val_loss: 275.0041\n",
      "Epoch 91/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 267.4001 - val_loss: 274.6093\n",
      "Epoch 92/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 267.0248 - val_loss: 274.2314\n",
      "Epoch 93/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 266.6712 - val_loss: 273.8702\n",
      "Epoch 94/6500\n",
      "27/27 [==============================] - 2s 73ms/step - loss: 266.3291 - val_loss: 273.5255\n",
      "Epoch 95/6500\n",
      "27/27 [==============================] - 2s 80ms/step - loss: 265.9944 - val_loss: 273.1949\n",
      "Epoch 96/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 265.6865 - val_loss: 272.8771\n",
      "Epoch 97/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 265.3893 - val_loss: 272.5756\n",
      "Epoch 98/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 265.0987 - val_loss: 272.2875\n",
      "Epoch 99/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 264.8329 - val_loss: 272.0108\n",
      "Epoch 100/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 264.5706 - val_loss: 271.7483\n",
      "Epoch 101/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 264.3263 - val_loss: 271.4966\n",
      "Epoch 102/6500\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 264.0942 - val_loss: 271.2579\n",
      "Epoch 103/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 263.8714 - val_loss: 271.0284\n",
      "Epoch 104/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 263.6613 - val_loss: 270.8103\n",
      "Epoch 105/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 263.4522 - val_loss: 270.6039\n",
      "Epoch 106/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 263.2662 - val_loss: 270.4048\n",
      "Epoch 107/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 263.0804 - val_loss: 270.2158\n",
      "Epoch 108/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 262.9086 - val_loss: 270.0367\n",
      "Epoch 109/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 262.7400 - val_loss: 269.8649\n",
      "Epoch 110/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 262.5812 - val_loss: 269.7033\n",
      "Epoch 111/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 262.4381 - val_loss: 269.5475\n",
      "Epoch 112/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 262.2976 - val_loss: 269.4007\n",
      "Epoch 113/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 262.1642 - val_loss: 269.2599\n",
      "Epoch 114/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 262.0374 - val_loss: 269.1278\n",
      "Epoch 115/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 261.9138 - val_loss: 269.0003\n",
      "Epoch 116/6500\n",
      "27/27 [==============================] - 2s 65ms/step - loss: 261.8001 - val_loss: 268.8810\n",
      "Epoch 117/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 261.6976 - val_loss: 268.7665\n",
      "Epoch 118/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 261.5947 - val_loss: 268.6581\n",
      "Epoch 119/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 261.4990 - val_loss: 268.5544\n",
      "Epoch 120/6500\n",
      "27/27 [==============================] - 2s 70ms/step - loss: 261.4050 - val_loss: 268.4578\n",
      "Epoch 121/6500\n",
      "27/27 [==============================] - 2s 88ms/step - loss: 261.3184 - val_loss: 268.3652\n",
      "Epoch 122/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 261.2381 - val_loss: 268.2772\n",
      "Epoch 123/6500\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 261.1635 - val_loss: 268.1951\n",
      "Epoch 124/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 261.0940 - val_loss: 268.1169\n",
      "Epoch 125/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 261.0204 - val_loss: 268.0422\n",
      "Epoch 126/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.9602 - val_loss: 267.9719\n",
      "Epoch 127/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.8967 - val_loss: 267.9042\n",
      "Epoch 128/6500\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 260.8406 - val_loss: 267.8412\n",
      "Epoch 129/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.7873 - val_loss: 267.7815\n",
      "Epoch 130/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.7351 - val_loss: 267.7254\n",
      "Epoch 131/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.6873 - val_loss: 267.6725\n",
      "Epoch 132/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.6419 - val_loss: 267.6220\n",
      "Epoch 133/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.6036 - val_loss: 267.5750\n",
      "Epoch 134/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.5624 - val_loss: 267.5307\n",
      "Epoch 135/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.5272 - val_loss: 267.4878\n",
      "Epoch 136/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.4936 - val_loss: 267.4479\n",
      "Epoch 137/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.4659 - val_loss: 267.4109\n",
      "Epoch 138/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.4316 - val_loss: 267.3758\n",
      "Epoch 139/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.4053 - val_loss: 267.3435\n",
      "Epoch 140/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.3791 - val_loss: 267.3127\n",
      "Epoch 141/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.3531 - val_loss: 267.2831\n",
      "Epoch 142/6500\n",
      "27/27 [==============================] - 3s 93ms/step - loss: 260.3311 - val_loss: 267.2556\n",
      "Epoch 143/6500\n",
      "27/27 [==============================] - 2s 67ms/step - loss: 260.3137 - val_loss: 267.2294\n",
      "Epoch 144/6500\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 260.2908 - val_loss: 267.2061\n",
      "Epoch 145/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.2749 - val_loss: 267.1830\n",
      "Epoch 146/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.2578 - val_loss: 267.1624\n",
      "Epoch 147/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.2419 - val_loss: 267.1437\n",
      "Epoch 148/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.2274 - val_loss: 267.1241\n",
      "Epoch 149/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.2138 - val_loss: 267.1076\n",
      "Epoch 150/6500\n",
      "27/27 [==============================] - 2s 93ms/step - loss: 260.2021 - val_loss: 267.0913\n",
      "Epoch 151/6500\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 260.1899 - val_loss: 267.0766\n",
      "Epoch 152/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.1817 - val_loss: 267.0625\n",
      "Epoch 153/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 99ms/step - loss: 260.1695 - val_loss: 267.0469\n",
      "Epoch 154/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.1601 - val_loss: 267.0351\n",
      "Epoch 155/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.1523 - val_loss: 267.0233\n",
      "Epoch 156/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 260.1416 - val_loss: 267.0120\n",
      "Epoch 157/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.1377 - val_loss: 267.0014\n",
      "Epoch 158/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.1304 - val_loss: 266.9917\n",
      "Epoch 159/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 260.1248 - val_loss: 266.9831\n",
      "Epoch 160/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.1221 - val_loss: 266.9741\n",
      "Epoch 161/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.1136 - val_loss: 266.9670\n",
      "Epoch 162/6500\n",
      "27/27 [==============================] - 2s 89ms/step - loss: 260.1077 - val_loss: 266.9596\n",
      "Epoch 163/6500\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 260.1051 - val_loss: 266.9529\n",
      "Epoch 164/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.1027 - val_loss: 266.9476\n",
      "Epoch 165/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0965 - val_loss: 266.9414\n",
      "Epoch 166/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0929 - val_loss: 266.9366\n",
      "Epoch 167/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0923 - val_loss: 266.9313\n",
      "Epoch 168/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0872 - val_loss: 266.9271\n",
      "Epoch 169/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0876 - val_loss: 266.9237\n",
      "Epoch 170/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0852 - val_loss: 266.9183\n",
      "Epoch 171/6500\n",
      "27/27 [==============================] - 3s 109ms/step - loss: 260.0830 - val_loss: 266.9146\n",
      "Epoch 172/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0810 - val_loss: 266.9106\n",
      "Epoch 173/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0790 - val_loss: 266.9091\n",
      "Epoch 174/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0793 - val_loss: 266.9060\n",
      "Epoch 175/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0761 - val_loss: 266.9034\n",
      "Epoch 176/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0766 - val_loss: 266.9011\n",
      "Epoch 177/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0751 - val_loss: 266.8967\n",
      "Epoch 178/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0765 - val_loss: 266.8972\n",
      "Epoch 179/6500\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 260.0760 - val_loss: 266.8945\n",
      "Epoch 180/6500\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 260.0728 - val_loss: 266.8899\n",
      "Epoch 181/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0717 - val_loss: 266.8896\n",
      "Epoch 182/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0723 - val_loss: 266.8881\n",
      "Epoch 183/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0701 - val_loss: 266.8868\n",
      "Epoch 184/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0683 - val_loss: 266.8846\n",
      "Epoch 185/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0674 - val_loss: 266.8852\n",
      "Epoch 186/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0665 - val_loss: 266.8829\n",
      "Epoch 187/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0674 - val_loss: 266.8808\n",
      "Epoch 188/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0661 - val_loss: 266.8806\n",
      "Epoch 189/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0678 - val_loss: 266.8793\n",
      "Epoch 190/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0679 - val_loss: 266.8784\n",
      "Epoch 191/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0661 - val_loss: 266.8771\n",
      "Epoch 192/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0668 - val_loss: 266.8775\n",
      "Epoch 193/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0658 - val_loss: 266.8759\n",
      "Epoch 194/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0663 - val_loss: 266.8759\n",
      "Epoch 195/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0648 - val_loss: 266.8761\n",
      "Epoch 196/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0647 - val_loss: 266.8765\n",
      "Epoch 197/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0649 - val_loss: 266.8766\n",
      "Epoch 198/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0646 - val_loss: 266.8742\n",
      "Epoch 199/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0626 - val_loss: 266.8749\n",
      "Epoch 200/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0663 - val_loss: 266.8747\n",
      "Epoch 201/6500\n",
      "27/27 [==============================] - 2s 82ms/step - loss: 260.0639 - val_loss: 266.8726\n",
      "Epoch 202/6500\n",
      "27/27 [==============================] - 2s 71ms/step - loss: 260.0641 - val_loss: 266.8748\n",
      "Epoch 203/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0619 - val_loss: 266.8738\n",
      "Epoch 204/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0634 - val_loss: 266.8733\n",
      "Epoch 205/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0612 - val_loss: 266.8733\n",
      "Epoch 206/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0623 - val_loss: 266.8725\n",
      "Epoch 207/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0609 - val_loss: 266.8720\n",
      "Epoch 208/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0609 - val_loss: 266.8707\n",
      "Epoch 209/6500\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 260.0634 - val_loss: 266.8716\n",
      "Epoch 210/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 260.0631 - val_loss: 266.8709\n",
      "Epoch 211/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0630 - val_loss: 266.8721\n",
      "Epoch 212/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0613 - val_loss: 266.8716\n",
      "Epoch 213/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0596 - val_loss: 266.8705\n",
      "Epoch 214/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0612 - val_loss: 266.8689\n",
      "Epoch 215/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0596 - val_loss: 266.8715\n",
      "Epoch 216/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0615 - val_loss: 266.8714\n",
      "Epoch 217/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0599 - val_loss: 266.8687\n",
      "Epoch 218/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0587 - val_loss: 266.8680\n",
      "Epoch 219/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0615 - val_loss: 266.8718\n",
      "Epoch 220/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0598 - val_loss: 266.8687\n",
      "Epoch 221/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0615 - val_loss: 266.8698\n",
      "Epoch 222/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0581 - val_loss: 266.8689\n",
      "Epoch 223/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 260.0587 - val_loss: 266.8689\n",
      "Epoch 224/6500\n",
      "27/27 [==============================] - 2s 93ms/step - loss: 260.0576 - val_loss: 266.8680\n",
      "Epoch 225/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0593 - val_loss: 266.8700\n",
      "Epoch 226/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0599 - val_loss: 266.8709\n",
      "Epoch 227/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0583 - val_loss: 266.8709\n",
      "Epoch 228/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 260.0561 - val_loss: 266.8700\n",
      "Epoch 229/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0569 - val_loss: 266.8689\n",
      "Epoch 230/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0579 - val_loss: 266.8689\n",
      "Epoch 231/6500\n",
      "27/27 [==============================] - 2s 88ms/step - loss: 260.0583 - val_loss: 266.8691\n",
      "Epoch 232/6500\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 260.0570 - val_loss: 266.8686\n",
      "Epoch 233/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0592 - val_loss: 266.8701\n",
      "Epoch 234/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0571 - val_loss: 266.8664\n",
      "Epoch 235/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0587 - val_loss: 266.8677\n",
      "Epoch 236/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0579 - val_loss: 266.8698\n",
      "Epoch 237/6500\n",
      "27/27 [==============================] - 2s 94ms/step - loss: 260.0563 - val_loss: 266.8672\n",
      "Epoch 238/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0570 - val_loss: 266.8677\n",
      "Epoch 239/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0558 - val_loss: 266.8677\n",
      "Epoch 240/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0571 - val_loss: 266.8689\n",
      "Epoch 241/6500\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 260.0563 - val_loss: 266.8692\n",
      "Epoch 242/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0572 - val_loss: 266.8705\n",
      "Epoch 243/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0551 - val_loss: 266.8693\n",
      "Epoch 244/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0574 - val_loss: 266.8698\n",
      "Epoch 245/6500\n",
      "27/27 [==============================] - 2s 79ms/step - loss: 260.0560 - val_loss: 266.8693\n",
      "Epoch 246/6500\n",
      "27/27 [==============================] - 2s 70ms/step - loss: 260.0553 - val_loss: 266.8677\n",
      "Epoch 247/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0565 - val_loss: 266.8708\n",
      "Epoch 248/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0551 - val_loss: 266.8705\n",
      "Epoch 249/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0547 - val_loss: 266.8700\n",
      "Epoch 250/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0567 - val_loss: 266.8691\n",
      "Epoch 251/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0571 - val_loss: 266.8679\n",
      "Epoch 252/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0544 - val_loss: 266.8669\n",
      "Epoch 253/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0565 - val_loss: 266.8658\n",
      "Epoch 254/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0553 - val_loss: 266.8710\n",
      "Epoch 255/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0545 - val_loss: 266.8690\n",
      "Epoch 256/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0547 - val_loss: 266.8685\n",
      "Epoch 257/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0540 - val_loss: 266.8688\n",
      "Epoch 258/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0558 - val_loss: 266.8681\n",
      "Epoch 259/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0540 - val_loss: 266.8683\n",
      "Epoch 260/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0542 - val_loss: 266.8663\n",
      "Epoch 261/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0544 - val_loss: 266.8670\n",
      "Epoch 262/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0543 - val_loss: 266.8676\n",
      "Epoch 263/6500\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 260.0544 - val_loss: 266.8681\n",
      "Epoch 264/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0539 - val_loss: 266.8670\n",
      "Epoch 265/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0561 - val_loss: 266.8679\n",
      "Epoch 266/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0545 - val_loss: 266.8663\n",
      "Epoch 267/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0538 - val_loss: 266.8662\n",
      "Epoch 268/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0542 - val_loss: 266.8680\n",
      "Epoch 269/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0558 - val_loss: 266.8669\n",
      "Epoch 270/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0567 - val_loss: 266.8708\n",
      "Epoch 271/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0533 - val_loss: 266.8689\n",
      "Epoch 272/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0553 - val_loss: 266.8703\n",
      "Epoch 273/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0530 - val_loss: 266.8687\n",
      "Epoch 274/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0536 - val_loss: 266.8710\n",
      "Epoch 275/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0538 - val_loss: 266.8698\n",
      "Epoch 276/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0538 - val_loss: 266.8694\n",
      "Epoch 277/6500\n",
      "27/27 [==============================] - 2s 90ms/step - loss: 260.0537 - val_loss: 266.8674\n",
      "Epoch 278/6500\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 260.0537 - val_loss: 266.8694\n",
      "Epoch 279/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0540 - val_loss: 266.8676\n",
      "Epoch 280/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0539 - val_loss: 266.8694\n",
      "Epoch 281/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0530 - val_loss: 266.8678\n",
      "Epoch 282/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0528 - val_loss: 266.8696\n",
      "Epoch 283/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 260.0537 - val_loss: 266.8655\n",
      "Epoch 284/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0537 - val_loss: 266.8632\n",
      "Epoch 285/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0531 - val_loss: 266.8647\n",
      "Epoch 286/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0529 - val_loss: 266.8687\n",
      "Epoch 287/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0527 - val_loss: 266.8691\n",
      "Epoch 288/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0549 - val_loss: 266.8721\n",
      "Epoch 289/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0530 - val_loss: 266.8687\n",
      "Epoch 290/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0530 - val_loss: 266.8658\n",
      "Epoch 291/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0532 - val_loss: 266.8661\n",
      "Epoch 292/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0519 - val_loss: 266.8668\n",
      "Epoch 293/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0528 - val_loss: 266.8689\n",
      "Epoch 294/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0539 - val_loss: 266.8710\n",
      "Epoch 295/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0518 - val_loss: 266.8701\n",
      "Epoch 296/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0531 - val_loss: 266.8678\n",
      "Epoch 297/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0516 - val_loss: 266.8670\n",
      "Epoch 298/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0533 - val_loss: 266.8685\n",
      "Epoch 299/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0514 - val_loss: 266.8680\n",
      "Epoch 300/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0534 - val_loss: 266.8664\n",
      "Epoch 301/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0523 - val_loss: 266.8701\n",
      "Epoch 302/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0528 - val_loss: 266.8704\n",
      "Epoch 303/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0512 - val_loss: 266.8689\n",
      "Epoch 304/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0529 - val_loss: 266.8642\n",
      "Epoch 305/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0552 - val_loss: 266.8692\n",
      "Epoch 306/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0518 - val_loss: 266.8692\n",
      "Epoch 307/6500\n",
      "27/27 [==============================] - 2s 76ms/step - loss: 260.0521 - val_loss: 266.8660\n",
      "Epoch 308/6500\n",
      "27/27 [==============================] - 2s 71ms/step - loss: 260.0517 - val_loss: 266.8664\n",
      "Epoch 309/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0533 - val_loss: 266.8670\n",
      "Epoch 310/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0522 - val_loss: 266.8657\n",
      "Epoch 311/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0517 - val_loss: 266.8673\n",
      "Epoch 312/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0509 - val_loss: 266.8714\n",
      "Epoch 313/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0526 - val_loss: 266.8690\n",
      "Epoch 314/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0527 - val_loss: 266.8636\n",
      "Epoch 315/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0515 - val_loss: 266.8661\n",
      "Epoch 316/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0516 - val_loss: 266.8633\n",
      "Epoch 317/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0505 - val_loss: 266.8687\n",
      "Epoch 318/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0509 - val_loss: 266.8701\n",
      "Epoch 319/6500\n",
      "27/27 [==============================] - 2s 88ms/step - loss: 260.0513 - val_loss: 266.8667\n",
      "Epoch 320/6500\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 260.0525 - val_loss: 266.8664\n",
      "Epoch 321/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0516 - val_loss: 266.8644\n",
      "Epoch 322/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0501 - val_loss: 266.8648\n",
      "Epoch 323/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0522 - val_loss: 266.8674\n",
      "Epoch 324/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0508 - val_loss: 266.8691\n",
      "Epoch 325/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0526 - val_loss: 266.8697\n",
      "Epoch 326/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0508 - val_loss: 266.8674\n",
      "Epoch 327/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0511 - val_loss: 266.8698\n",
      "Epoch 328/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0525 - val_loss: 266.8648\n",
      "Epoch 329/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0504 - val_loss: 266.8671\n",
      "Epoch 330/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0511 - val_loss: 266.8717\n",
      "Epoch 331/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0516 - val_loss: 266.8714\n",
      "Epoch 332/6500\n",
      "27/27 [==============================] - 2s 93ms/step - loss: 260.0523 - val_loss: 266.8664\n",
      "Epoch 333/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 260.0523 - val_loss: 266.8687\n",
      "Epoch 334/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0506 - val_loss: 266.8671\n",
      "Epoch 335/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0506 - val_loss: 266.8689\n",
      "Epoch 336/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0498 - val_loss: 266.8652\n",
      "Epoch 337/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0521 - val_loss: 266.8639\n",
      "Epoch 338/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 260.0529 - val_loss: 266.8629\n",
      "Epoch 339/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0499 - val_loss: 266.8677\n",
      "Epoch 340/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0503 - val_loss: 266.8654\n",
      "Epoch 341/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0505 - val_loss: 266.8655\n",
      "Epoch 342/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0504 - val_loss: 266.8653\n",
      "Epoch 343/6500\n",
      "27/27 [==============================] - 2s 55ms/step - loss: 260.0502 - val_loss: 266.8651\n",
      "Epoch 344/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0518 - val_loss: 266.8596\n",
      "Epoch 345/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0519 - val_loss: 266.8665\n",
      "Epoch 346/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0507 - val_loss: 266.8657\n",
      "Epoch 347/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0509 - val_loss: 266.8648\n",
      "Epoch 348/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0526 - val_loss: 266.8667\n",
      "Epoch 349/6500\n",
      "27/27 [==============================] - 3s 108ms/step - loss: 260.0504 - val_loss: 266.8651\n",
      "Epoch 350/6500\n",
      "27/27 [==============================] - 3s 110ms/step - loss: 260.0510 - val_loss: 266.8641\n",
      "Epoch 351/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0511 - val_loss: 266.8632\n",
      "Epoch 352/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0496 - val_loss: 266.8671\n",
      "Epoch 353/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 260.0521 - val_loss: 266.8676\n",
      "Epoch 354/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0486 - val_loss: 266.8731\n",
      "Epoch 355/6500\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 260.0520 - val_loss: 266.8727\n",
      "Epoch 356/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0500 - val_loss: 266.8657\n",
      "Epoch 357/6500\n",
      "27/27 [==============================] - 2s 91ms/step - loss: 260.0511 - val_loss: 266.8687\n",
      "Epoch 358/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0490 - val_loss: 266.8685\n",
      "Epoch 359/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0514 - val_loss: 266.8730\n",
      "Epoch 360/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0509 - val_loss: 266.8676\n",
      "Epoch 361/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0500 - val_loss: 266.8659\n",
      "Epoch 362/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0508 - val_loss: 266.8633\n",
      "Epoch 363/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0488 - val_loss: 266.8690\n",
      "Epoch 364/6500\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 260.0492 - val_loss: 266.8666\n",
      "Epoch 365/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0500 - val_loss: 266.8634\n",
      "Epoch 366/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0501 - val_loss: 266.8618\n",
      "Epoch 367/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0500 - val_loss: 266.8692\n",
      "Epoch 368/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0492 - val_loss: 266.8737\n",
      "Epoch 369/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0499 - val_loss: 266.8690\n",
      "Epoch 370/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0509 - val_loss: 266.8657\n",
      "Epoch 371/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0515 - val_loss: 266.8737\n",
      "Epoch 372/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0497 - val_loss: 266.8696\n",
      "Epoch 373/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0499 - val_loss: 266.8690\n",
      "Epoch 374/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0490 - val_loss: 266.8650\n",
      "Epoch 375/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0490 - val_loss: 266.8659\n",
      "Epoch 376/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0504 - val_loss: 266.8635\n",
      "Epoch 377/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0491 - val_loss: 266.8639\n",
      "Epoch 378/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0522 - val_loss: 266.8631\n",
      "Epoch 379/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0490 - val_loss: 266.8672\n",
      "Epoch 380/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0485 - val_loss: 266.8649\n",
      "Epoch 381/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0490 - val_loss: 266.8657\n",
      "Epoch 382/6500\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 260.0496 - val_loss: 266.8663\n",
      "Epoch 383/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 260.0486 - val_loss: 266.8652\n",
      "Epoch 384/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0506 - val_loss: 266.8695\n",
      "Epoch 385/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0483 - val_loss: 266.8639\n",
      "Epoch 386/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0499 - val_loss: 266.8656\n",
      "Epoch 387/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0492 - val_loss: 266.8642\n",
      "Epoch 388/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0499 - val_loss: 266.8664\n",
      "Epoch 389/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0490 - val_loss: 266.8663\n",
      "Epoch 390/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0517 - val_loss: 266.8677\n",
      "Epoch 391/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0479 - val_loss: 266.8651\n",
      "Epoch 392/6500\n",
      "27/27 [==============================] - 3s 107ms/step - loss: 260.0481 - val_loss: 266.8674\n",
      "Epoch 393/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0501 - val_loss: 266.8667\n",
      "Epoch 394/6500\n",
      "27/27 [==============================] - 2s 73ms/step - loss: 260.0485 - val_loss: 266.8628\n",
      "Epoch 395/6500\n",
      "27/27 [==============================] - 2s 74ms/step - loss: 260.0483 - val_loss: 266.8686\n",
      "Epoch 396/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0487 - val_loss: 266.8715\n",
      "Epoch 397/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0495 - val_loss: 266.8694\n",
      "Epoch 398/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0494 - val_loss: 266.8629\n",
      "Epoch 399/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0491 - val_loss: 266.8641\n",
      "Epoch 400/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0507 - val_loss: 266.8656\n",
      "Epoch 401/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0488 - val_loss: 266.8665\n",
      "Epoch 402/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0495 - val_loss: 266.8642\n",
      "Epoch 403/6500\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 260.0489 - val_loss: 266.8636\n",
      "Epoch 404/6500\n",
      "27/27 [==============================] - 2s 88ms/step - loss: 260.0487 - val_loss: 266.8712\n",
      "Epoch 405/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0483 - val_loss: 266.8678\n",
      "Epoch 406/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0488 - val_loss: 266.8679\n",
      "Epoch 407/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0482 - val_loss: 266.8644\n",
      "Epoch 408/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0486 - val_loss: 266.8656\n",
      "Epoch 409/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0494 - val_loss: 266.8627\n",
      "Epoch 410/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0480 - val_loss: 266.8647\n",
      "Epoch 411/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0478 - val_loss: 266.8681\n",
      "Epoch 412/6500\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 260.0494 - val_loss: 266.8657\n",
      "Epoch 413/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 260.0486 - val_loss: 266.8671\n",
      "Epoch 414/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0495 - val_loss: 266.8700\n",
      "Epoch 415/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0479 - val_loss: 266.8650\n",
      "Epoch 416/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0480 - val_loss: 266.8631\n",
      "Epoch 417/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0479 - val_loss: 266.8640\n",
      "Epoch 418/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0486 - val_loss: 266.8661\n",
      "Epoch 419/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0500 - val_loss: 266.8653\n",
      "Epoch 420/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0496 - val_loss: 266.8597\n",
      "Epoch 421/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0469 - val_loss: 266.8668\n",
      "Epoch 422/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0475 - val_loss: 266.8673\n",
      "Epoch 423/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0494 - val_loss: 266.8696\n",
      "Epoch 424/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0478 - val_loss: 266.8636\n",
      "Epoch 425/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0474 - val_loss: 266.8661\n",
      "Epoch 426/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0491 - val_loss: 266.8626\n",
      "Epoch 427/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0484 - val_loss: 266.8646\n",
      "Epoch 428/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0484 - val_loss: 266.8610\n",
      "Epoch 429/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0495 - val_loss: 266.8616\n",
      "Epoch 430/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0479 - val_loss: 266.8657\n",
      "Epoch 431/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0481 - val_loss: 266.8614\n",
      "Epoch 432/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0497 - val_loss: 266.8665\n",
      "Epoch 433/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0487 - val_loss: 266.8702\n",
      "Epoch 434/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0478 - val_loss: 266.8649\n",
      "Epoch 435/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0478 - val_loss: 266.8621\n",
      "Epoch 436/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0476 - val_loss: 266.8641\n",
      "Epoch 437/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0506 - val_loss: 266.8683\n",
      "Epoch 438/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0518 - val_loss: 266.8601\n",
      "Epoch 439/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0487 - val_loss: 266.8597\n",
      "Epoch 440/6500\n",
      "27/27 [==============================] - 2s 90ms/step - loss: 260.0482 - val_loss: 266.8601\n",
      "Epoch 441/6500\n",
      "27/27 [==============================] - 2s 58ms/step - loss: 260.0481 - val_loss: 266.8617\n",
      "Epoch 442/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0475 - val_loss: 266.8667\n",
      "Epoch 443/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0480 - val_loss: 266.8605\n",
      "Epoch 444/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0483 - val_loss: 266.8620\n",
      "Epoch 445/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0486 - val_loss: 266.8638\n",
      "Epoch 446/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0482 - val_loss: 266.8639\n",
      "Epoch 447/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0473 - val_loss: 266.8647\n",
      "Epoch 448/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0469 - val_loss: 266.8611\n",
      "Epoch 449/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0482 - val_loss: 266.8648\n",
      "Epoch 450/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0471 - val_loss: 266.8677\n",
      "Epoch 451/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0498 - val_loss: 266.8693\n",
      "Epoch 452/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0497 - val_loss: 266.8613\n",
      "Epoch 453/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0475 - val_loss: 266.8623\n",
      "Epoch 454/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0500 - val_loss: 266.8692\n",
      "Epoch 455/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0468 - val_loss: 266.8671\n",
      "Epoch 456/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0469 - val_loss: 266.8630\n",
      "Epoch 457/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0474 - val_loss: 266.8621\n",
      "Epoch 458/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0479 - val_loss: 266.8661\n",
      "Epoch 459/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0489 - val_loss: 266.8679\n",
      "Epoch 460/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0475 - val_loss: 266.8625\n",
      "Epoch 461/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0469 - val_loss: 266.8626\n",
      "Epoch 462/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0480 - val_loss: 266.8639\n",
      "Epoch 463/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0490 - val_loss: 266.8691\n",
      "Epoch 464/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0465 - val_loss: 266.8660\n",
      "Epoch 465/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0476 - val_loss: 266.8645\n",
      "Epoch 466/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0471 - val_loss: 266.8682\n",
      "Epoch 467/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0497 - val_loss: 266.8612\n",
      "Epoch 468/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0473 - val_loss: 266.8670\n",
      "Epoch 469/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0466 - val_loss: 266.8630\n",
      "Epoch 470/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0471 - val_loss: 266.8657\n",
      "Epoch 471/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0480 - val_loss: 266.8672\n",
      "Epoch 472/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0464 - val_loss: 266.8698\n",
      "Epoch 473/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0473 - val_loss: 266.8666\n",
      "Epoch 474/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0484 - val_loss: 266.8595\n",
      "Epoch 475/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0465 - val_loss: 266.8642\n",
      "Epoch 476/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0477 - val_loss: 266.8623\n",
      "Epoch 477/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0475 - val_loss: 266.8644\n",
      "Epoch 478/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0471 - val_loss: 266.8685\n",
      "Epoch 479/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0466 - val_loss: 266.8648\n",
      "Epoch 480/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0501 - val_loss: 266.8665\n",
      "Epoch 481/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0497 - val_loss: 266.8652\n",
      "Epoch 482/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0475 - val_loss: 266.8698\n",
      "Epoch 483/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0483 - val_loss: 266.8677\n",
      "Epoch 484/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0469 - val_loss: 266.8651\n",
      "Epoch 485/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0473 - val_loss: 266.8650\n",
      "Epoch 486/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0460 - val_loss: 266.8663\n",
      "Epoch 487/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0480 - val_loss: 266.8586\n",
      "Epoch 488/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0471 - val_loss: 266.8683\n",
      "Epoch 489/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0469 - val_loss: 266.8644\n",
      "Epoch 490/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0464 - val_loss: 266.8617\n",
      "Epoch 491/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0476 - val_loss: 266.8690\n",
      "Epoch 492/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0468 - val_loss: 266.8651\n",
      "Epoch 493/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0464 - val_loss: 266.8689\n",
      "Epoch 494/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0468 - val_loss: 266.8645\n",
      "Epoch 495/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0458 - val_loss: 266.8644\n",
      "Epoch 496/6500\n",
      "27/27 [==============================] - 2s 94ms/step - loss: 260.0463 - val_loss: 266.8629\n",
      "Epoch 497/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0468 - val_loss: 266.8672\n",
      "Epoch 498/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0468 - val_loss: 266.8631\n",
      "Epoch 499/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 260.0477 - val_loss: 266.8662\n",
      "Epoch 500/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0464 - val_loss: 266.8620\n",
      "Epoch 501/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0467 - val_loss: 266.8648\n",
      "Epoch 502/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0462 - val_loss: 266.8659\n",
      "Epoch 503/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0469 - val_loss: 266.8614\n",
      "Epoch 504/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0468 - val_loss: 266.8623\n",
      "Epoch 505/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0470 - val_loss: 266.8638\n",
      "Epoch 506/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0457 - val_loss: 266.8637\n",
      "Epoch 507/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0466 - val_loss: 266.8679\n",
      "Epoch 508/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0462 - val_loss: 266.8681\n",
      "Epoch 509/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0475 - val_loss: 266.8645\n",
      "Epoch 510/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0457 - val_loss: 266.8682\n",
      "Epoch 511/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0459 - val_loss: 266.8651\n",
      "Epoch 512/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0462 - val_loss: 266.8637\n",
      "Epoch 513/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0471 - val_loss: 266.8698\n",
      "Epoch 514/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0469 - val_loss: 266.8623\n",
      "Epoch 515/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0465 - val_loss: 266.8654\n",
      "Epoch 516/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0469 - val_loss: 266.8647\n",
      "Epoch 517/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0457 - val_loss: 266.8670\n",
      "Epoch 518/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0483 - val_loss: 266.8703\n",
      "Epoch 519/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0458 - val_loss: 266.8631\n",
      "Epoch 520/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0467 - val_loss: 266.8641\n",
      "Epoch 521/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0473 - val_loss: 266.8665\n",
      "Epoch 522/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0466 - val_loss: 266.8669\n",
      "Epoch 523/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0467 - val_loss: 266.8673\n",
      "Epoch 524/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0461 - val_loss: 266.8634\n",
      "Epoch 525/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0468 - val_loss: 266.8688\n",
      "Epoch 526/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0454 - val_loss: 266.8661\n",
      "Epoch 527/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0462 - val_loss: 266.8660\n",
      "Epoch 528/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0463 - val_loss: 266.8661\n",
      "Epoch 529/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0468 - val_loss: 266.8701\n",
      "Epoch 530/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0464 - val_loss: 266.8640\n",
      "Epoch 531/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0460 - val_loss: 266.8594\n",
      "Epoch 532/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0464 - val_loss: 266.8612\n",
      "Epoch 533/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0459 - val_loss: 266.8672\n",
      "Epoch 534/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0453 - val_loss: 266.8644\n",
      "Epoch 535/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0461 - val_loss: 266.8626\n",
      "Epoch 536/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0458 - val_loss: 266.8623\n",
      "Epoch 537/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0464 - val_loss: 266.8640\n",
      "Epoch 538/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0459 - val_loss: 266.8647\n",
      "Epoch 539/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0453 - val_loss: 266.8636\n",
      "Epoch 540/6500\n",
      "27/27 [==============================] - 3s 93ms/step - loss: 260.0455 - val_loss: 266.8632\n",
      "Epoch 541/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0458 - val_loss: 266.8651\n",
      "Epoch 542/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0458 - val_loss: 266.8618\n",
      "Epoch 543/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0457 - val_loss: 266.8662\n",
      "Epoch 544/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0458 - val_loss: 266.8641\n",
      "Epoch 545/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0452 - val_loss: 266.8653\n",
      "Epoch 546/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0468 - val_loss: 266.8595\n",
      "Epoch 547/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0465 - val_loss: 266.8639\n",
      "Epoch 548/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0460 - val_loss: 266.8658\n",
      "Epoch 549/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0463 - val_loss: 266.8619\n",
      "Epoch 550/6500\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 260.0461 - val_loss: 266.8669\n",
      "Epoch 551/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0461 - val_loss: 266.8626\n",
      "Epoch 552/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0463 - val_loss: 266.8652\n",
      "Epoch 553/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0482 - val_loss: 266.8739\n",
      "Epoch 554/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0462 - val_loss: 266.8701\n",
      "Epoch 555/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0449 - val_loss: 266.8630\n",
      "Epoch 556/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0470 - val_loss: 266.8633\n",
      "Epoch 557/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0481 - val_loss: 266.8623\n",
      "Epoch 558/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0468 - val_loss: 266.8687\n",
      "Epoch 559/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0457 - val_loss: 266.8673\n",
      "Epoch 560/6500\n",
      "27/27 [==============================] - 2s 91ms/step - loss: 260.0471 - val_loss: 266.8646\n",
      "Epoch 561/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0455 - val_loss: 266.8646\n",
      "Epoch 562/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0458 - val_loss: 266.8613\n",
      "Epoch 563/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0454 - val_loss: 266.8674\n",
      "Epoch 564/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0455 - val_loss: 266.8680\n",
      "Epoch 565/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0461 - val_loss: 266.8596\n",
      "Epoch 566/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0462 - val_loss: 266.8633\n",
      "Epoch 567/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0458 - val_loss: 266.8610\n",
      "Epoch 568/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0463 - val_loss: 266.8661\n",
      "Epoch 569/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0457 - val_loss: 266.8643\n",
      "Epoch 570/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0456 - val_loss: 266.8593\n",
      "Epoch 571/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0457 - val_loss: 266.8655\n",
      "Epoch 572/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0458 - val_loss: 266.8679\n",
      "Epoch 573/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0488 - val_loss: 266.8581\n",
      "Epoch 574/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0462 - val_loss: 266.8657\n",
      "Epoch 575/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0450 - val_loss: 266.8687\n",
      "Epoch 576/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0456 - val_loss: 266.8630\n",
      "Epoch 577/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0450 - val_loss: 266.8644\n",
      "Epoch 578/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0451 - val_loss: 266.8638\n",
      "Epoch 579/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0463 - val_loss: 266.8642\n",
      "Epoch 580/6500\n",
      "27/27 [==============================] - 2s 93ms/step - loss: 260.0464 - val_loss: 266.8639\n",
      "Epoch 581/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 260.0459 - val_loss: 266.8628\n",
      "Epoch 582/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0463 - val_loss: 266.8570\n",
      "Epoch 583/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0464 - val_loss: 266.8593\n",
      "Epoch 584/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0451 - val_loss: 266.8644\n",
      "Epoch 585/6500\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 260.0456 - val_loss: 266.8642\n",
      "Epoch 586/6500\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 260.0451 - val_loss: 266.8646\n",
      "Epoch 587/6500\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 260.0455 - val_loss: 266.8660\n",
      "Epoch 588/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0456 - val_loss: 266.8644\n",
      "Epoch 589/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0456 - val_loss: 266.8643\n",
      "Epoch 590/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0457 - val_loss: 266.8638\n",
      "Epoch 591/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0461 - val_loss: 266.8558\n",
      "Epoch 592/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0460 - val_loss: 266.8633\n",
      "Epoch 593/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0453 - val_loss: 266.8639\n",
      "Epoch 594/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0451 - val_loss: 266.8618\n",
      "Epoch 595/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0450 - val_loss: 266.8663\n",
      "Epoch 596/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0457 - val_loss: 266.8592\n",
      "Epoch 597/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0451 - val_loss: 266.8615\n",
      "Epoch 598/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0453 - val_loss: 266.8657\n",
      "Epoch 599/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0450 - val_loss: 266.8652\n",
      "Epoch 600/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0458 - val_loss: 266.8651\n",
      "Epoch 601/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0451 - val_loss: 266.8616\n",
      "Epoch 602/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0461 - val_loss: 266.8632\n",
      "Epoch 603/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0448 - val_loss: 266.8631\n",
      "Epoch 604/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0458 - val_loss: 266.8602\n",
      "Epoch 605/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0453 - val_loss: 266.8664\n",
      "Epoch 606/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0471 - val_loss: 266.8619\n",
      "Epoch 607/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0450 - val_loss: 266.8629\n",
      "Epoch 608/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0456 - val_loss: 266.8670\n",
      "Epoch 609/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0448 - val_loss: 266.8675\n",
      "Epoch 610/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0458 - val_loss: 266.8670\n",
      "Epoch 611/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0449 - val_loss: 266.8671\n",
      "Epoch 612/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0448 - val_loss: 266.8686\n",
      "Epoch 613/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 260.0445 - val_loss: 266.8651\n",
      "Epoch 614/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0461 - val_loss: 266.8617\n",
      "Epoch 615/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0470 - val_loss: 266.8575\n",
      "Epoch 616/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0466 - val_loss: 266.8573\n",
      "Epoch 617/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0458 - val_loss: 266.8580\n",
      "Epoch 618/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0455 - val_loss: 266.8664\n",
      "Epoch 619/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0458 - val_loss: 266.8630\n",
      "Epoch 620/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0454 - val_loss: 266.8623\n",
      "Epoch 621/6500\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 260.0474 - val_loss: 266.8665\n",
      "Epoch 622/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0464 - val_loss: 266.8612\n",
      "Epoch 623/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0455 - val_loss: 266.8591\n",
      "Epoch 624/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0450 - val_loss: 266.8653\n",
      "Epoch 625/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0459 - val_loss: 266.8668\n",
      "Epoch 626/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0452 - val_loss: 266.8609\n",
      "Epoch 627/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0453 - val_loss: 266.8644\n",
      "Epoch 628/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0451 - val_loss: 266.8646\n",
      "Epoch 629/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0449 - val_loss: 266.8629\n",
      "Epoch 630/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0459 - val_loss: 266.8598\n",
      "Epoch 631/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0447 - val_loss: 266.8661\n",
      "Epoch 632/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0443 - val_loss: 266.8652\n",
      "Epoch 633/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0469 - val_loss: 266.8663\n",
      "Epoch 634/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0446 - val_loss: 266.8593\n",
      "Epoch 635/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0451 - val_loss: 266.8618\n",
      "Epoch 636/6500\n",
      "27/27 [==============================] - 2s 89ms/step - loss: 260.0451 - val_loss: 266.8679\n",
      "Epoch 637/6500\n",
      "27/27 [==============================] - 2s 63ms/step - loss: 260.0457 - val_loss: 266.8655\n",
      "Epoch 638/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0458 - val_loss: 266.8633\n",
      "Epoch 639/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0443 - val_loss: 266.8637\n",
      "Epoch 640/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0443 - val_loss: 266.8650\n",
      "Epoch 641/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0448 - val_loss: 266.8629\n",
      "Epoch 642/6500\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 260.0444 - val_loss: 266.8628\n",
      "Epoch 643/6500\n",
      "27/27 [==============================] - 2s 64ms/step - loss: 260.0470 - val_loss: 266.8675\n",
      "Epoch 644/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0450 - val_loss: 266.8658\n",
      "Epoch 645/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0443 - val_loss: 266.8635\n",
      "Epoch 646/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0461 - val_loss: 266.8640\n",
      "Epoch 647/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0456 - val_loss: 266.8587\n",
      "Epoch 648/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0450 - val_loss: 266.8639\n",
      "Epoch 649/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0445 - val_loss: 266.8674\n",
      "Epoch 650/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0448 - val_loss: 266.8658\n",
      "Epoch 651/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0448 - val_loss: 266.8688\n",
      "Epoch 652/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0446 - val_loss: 266.8671\n",
      "Epoch 653/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0448 - val_loss: 266.8626\n",
      "Epoch 654/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0450 - val_loss: 266.8619\n",
      "Epoch 655/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0458 - val_loss: 266.8707\n",
      "Epoch 656/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0461 - val_loss: 266.8630\n",
      "Epoch 657/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0439 - val_loss: 266.8662\n",
      "Epoch 658/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0442 - val_loss: 266.8640\n",
      "Epoch 659/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0461 - val_loss: 266.8684\n",
      "Epoch 660/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0446 - val_loss: 266.8625\n",
      "Epoch 661/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0460 - val_loss: 266.8616\n",
      "Epoch 662/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0441 - val_loss: 266.8622\n",
      "Epoch 663/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0451 - val_loss: 266.8611\n",
      "Epoch 664/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0445 - val_loss: 266.8606\n",
      "Epoch 665/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0453 - val_loss: 266.8596\n",
      "Epoch 666/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0444 - val_loss: 266.8627\n",
      "Epoch 667/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0449 - val_loss: 266.8598\n",
      "Epoch 668/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0439 - val_loss: 266.8634\n",
      "Epoch 669/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0450 - val_loss: 266.8623\n",
      "Epoch 670/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0443 - val_loss: 266.8638\n",
      "Epoch 671/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0443 - val_loss: 266.8686\n",
      "Epoch 672/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0444 - val_loss: 266.8677\n",
      "Epoch 673/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0443 - val_loss: 266.8615\n",
      "Epoch 674/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0451 - val_loss: 266.8661\n",
      "Epoch 675/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0452 - val_loss: 266.8622\n",
      "Epoch 676/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0447 - val_loss: 266.8626\n",
      "Epoch 677/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0440 - val_loss: 266.8600\n",
      "Epoch 678/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0446 - val_loss: 266.8635\n",
      "Epoch 679/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0442 - val_loss: 266.8646\n",
      "Epoch 680/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0450 - val_loss: 266.8668\n",
      "Epoch 681/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0452 - val_loss: 266.8606\n",
      "Epoch 682/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0452 - val_loss: 266.8579\n",
      "Epoch 683/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0438 - val_loss: 266.8655\n",
      "Epoch 684/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0454 - val_loss: 266.8668\n",
      "Epoch 685/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0468 - val_loss: 266.8553\n",
      "Epoch 686/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0453 - val_loss: 266.8607\n",
      "Epoch 687/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0442 - val_loss: 266.8637\n",
      "Epoch 688/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0453 - val_loss: 266.8602\n",
      "Epoch 689/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0452 - val_loss: 266.8661\n",
      "Epoch 690/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0440 - val_loss: 266.8613\n",
      "Epoch 691/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0437 - val_loss: 266.8619\n",
      "Epoch 692/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0450 - val_loss: 266.8609\n",
      "Epoch 693/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0448 - val_loss: 266.8625\n",
      "Epoch 694/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0446 - val_loss: 266.8652\n",
      "Epoch 695/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0449 - val_loss: 266.8642\n",
      "Epoch 696/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0455 - val_loss: 266.8682\n",
      "Epoch 697/6500\n",
      "27/27 [==============================] - 2s 86ms/step - loss: 260.0440 - val_loss: 266.8628\n",
      "Epoch 698/6500\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 260.0445 - val_loss: 266.8616\n",
      "Epoch 699/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0457 - val_loss: 266.8637\n",
      "Epoch 700/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0451 - val_loss: 266.8614\n",
      "Epoch 701/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0439 - val_loss: 266.8637\n",
      "Epoch 702/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0444 - val_loss: 266.8648\n",
      "Epoch 703/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0449 - val_loss: 266.8690\n",
      "Epoch 704/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0434 - val_loss: 266.8619\n",
      "Epoch 705/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0442 - val_loss: 266.8645\n",
      "Epoch 706/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0457 - val_loss: 266.8623\n",
      "Epoch 707/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0446 - val_loss: 266.8620\n",
      "Epoch 708/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0457 - val_loss: 266.8639\n",
      "Epoch 709/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0433 - val_loss: 266.8582\n",
      "Epoch 710/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0447 - val_loss: 266.8594\n",
      "Epoch 711/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0446 - val_loss: 266.8649\n",
      "Epoch 712/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0447 - val_loss: 266.8600\n",
      "Epoch 713/6500\n",
      "27/27 [==============================] - 1s 47ms/step - loss: 260.0449 - val_loss: 266.8596\n",
      "Epoch 714/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0460 - val_loss: 266.8640\n",
      "Epoch 715/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0441 - val_loss: 266.8614\n",
      "Epoch 716/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0438 - val_loss: 266.8625\n",
      "Epoch 717/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0443 - val_loss: 266.8594\n",
      "Epoch 718/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0460 - val_loss: 266.8630\n",
      "Epoch 719/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0480 - val_loss: 266.8604\n",
      "Epoch 720/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0448 - val_loss: 266.8645\n",
      "Epoch 721/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0450 - val_loss: 266.8636\n",
      "Epoch 722/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0451 - val_loss: 266.8643\n",
      "Epoch 723/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0475 - val_loss: 266.8629\n",
      "Epoch 724/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0444 - val_loss: 266.8626\n",
      "Epoch 725/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0436 - val_loss: 266.8651\n",
      "Epoch 726/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0449 - val_loss: 266.8704\n",
      "Epoch 727/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0462 - val_loss: 266.8629\n",
      "Epoch 728/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0436 - val_loss: 266.8651\n",
      "Epoch 729/6500\n",
      "27/27 [==============================] - 2s 93ms/step - loss: 260.0437 - val_loss: 266.8630\n",
      "Epoch 730/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0438 - val_loss: 266.8657\n",
      "Epoch 731/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0439 - val_loss: 266.8625\n",
      "Epoch 732/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0451 - val_loss: 266.8630\n",
      "Epoch 733/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0454 - val_loss: 266.8607\n",
      "Epoch 734/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0439 - val_loss: 266.8641\n",
      "Epoch 735/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0435 - val_loss: 266.8654\n",
      "Epoch 736/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0453 - val_loss: 266.8648\n",
      "Epoch 737/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0443 - val_loss: 266.8616\n",
      "Epoch 738/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0439 - val_loss: 266.8613\n",
      "Epoch 739/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0433 - val_loss: 266.8611\n",
      "Epoch 740/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0442 - val_loss: 266.8603\n",
      "Epoch 741/6500\n",
      "27/27 [==============================] - 2s 74ms/step - loss: 260.0447 - val_loss: 266.8613\n",
      "Epoch 742/6500\n",
      "27/27 [==============================] - 2s 74ms/step - loss: 260.0448 - val_loss: 266.8621\n",
      "Epoch 743/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0433 - val_loss: 266.8660\n",
      "Epoch 744/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0450 - val_loss: 266.8611\n",
      "Epoch 745/6500\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 260.0441 - val_loss: 266.8655\n",
      "Epoch 746/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0447 - val_loss: 266.8590\n",
      "Epoch 747/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0436 - val_loss: 266.8658\n",
      "Epoch 748/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0444 - val_loss: 266.8611\n",
      "Epoch 749/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0437 - val_loss: 266.8654\n",
      "Epoch 750/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0440 - val_loss: 266.8619\n",
      "Epoch 751/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0438 - val_loss: 266.8625\n",
      "Epoch 752/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0441 - val_loss: 266.8662\n",
      "Epoch 753/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0452 - val_loss: 266.8634\n",
      "Epoch 754/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0434 - val_loss: 266.8642\n",
      "Epoch 755/6500\n",
      "27/27 [==============================] - 2s 91ms/step - loss: 260.0435 - val_loss: 266.8604\n",
      "Epoch 756/6500\n",
      "27/27 [==============================] - 2s 57ms/step - loss: 260.0438 - val_loss: 266.8578\n",
      "Epoch 757/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0434 - val_loss: 266.8600\n",
      "Epoch 758/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0438 - val_loss: 266.8625\n",
      "Epoch 759/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0443 - val_loss: 266.8626\n",
      "Epoch 760/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0434 - val_loss: 266.8611\n",
      "Epoch 761/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 94ms/step - loss: 260.0444 - val_loss: 266.8628\n",
      "Epoch 762/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0438 - val_loss: 266.8566\n",
      "Epoch 763/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0434 - val_loss: 266.8581\n",
      "Epoch 764/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0442 - val_loss: 266.8606\n",
      "Epoch 765/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0437 - val_loss: 266.8617\n",
      "Epoch 766/6500\n",
      "27/27 [==============================] - 2s 60ms/step - loss: 260.0438 - val_loss: 266.8585\n",
      "Epoch 767/6500\n",
      "27/27 [==============================] - 2s 86ms/step - loss: 260.0457 - val_loss: 266.8620\n",
      "Epoch 768/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0428 - val_loss: 266.8616\n",
      "Epoch 769/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0440 - val_loss: 266.8620\n",
      "Epoch 770/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0439 - val_loss: 266.8596\n",
      "Epoch 771/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0437 - val_loss: 266.8602\n",
      "Epoch 772/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0438 - val_loss: 266.8624\n",
      "Epoch 773/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0438 - val_loss: 266.8613\n",
      "Epoch 774/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0452 - val_loss: 266.8662\n",
      "Epoch 775/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0435 - val_loss: 266.8586\n",
      "Epoch 776/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0444 - val_loss: 266.8620\n",
      "Epoch 777/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0437 - val_loss: 266.8608\n",
      "Epoch 778/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0437 - val_loss: 266.8581\n",
      "Epoch 779/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0460 - val_loss: 266.8613\n",
      "Epoch 780/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0439 - val_loss: 266.8584\n",
      "Epoch 781/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0440 - val_loss: 266.8586\n",
      "Epoch 782/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0446 - val_loss: 266.8539\n",
      "Epoch 783/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0439 - val_loss: 266.8623\n",
      "Epoch 784/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0437 - val_loss: 266.8586\n",
      "Epoch 785/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0436 - val_loss: 266.8596\n",
      "Epoch 786/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0436 - val_loss: 266.8665\n",
      "Epoch 787/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0436 - val_loss: 266.8632\n",
      "Epoch 788/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0438 - val_loss: 266.8625\n",
      "Epoch 789/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0440 - val_loss: 266.8621\n",
      "Epoch 790/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0443 - val_loss: 266.8599\n",
      "Epoch 791/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0429 - val_loss: 266.8629\n",
      "Epoch 792/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0435 - val_loss: 266.8632\n",
      "Epoch 793/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0446 - val_loss: 266.8613\n",
      "Epoch 794/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0432 - val_loss: 266.8628\n",
      "Epoch 795/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0434 - val_loss: 266.8664\n",
      "Epoch 796/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0435 - val_loss: 266.8650\n",
      "Epoch 797/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0434 - val_loss: 266.8670\n",
      "Epoch 798/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0437 - val_loss: 266.8662\n",
      "Epoch 799/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 260.0435 - val_loss: 266.8644\n",
      "Epoch 800/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0435 - val_loss: 266.8636\n",
      "Epoch 801/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0438 - val_loss: 266.8600\n",
      "Epoch 802/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 260.0448 - val_loss: 266.8652\n",
      "Epoch 803/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0442 - val_loss: 266.8628\n",
      "Epoch 804/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0431 - val_loss: 266.8612\n",
      "Epoch 805/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 260.0444 - val_loss: 266.8594\n",
      "Epoch 806/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0447 - val_loss: 266.8635\n",
      "Epoch 807/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0428 - val_loss: 266.8596\n",
      "Epoch 808/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0434 - val_loss: 266.8637\n",
      "Epoch 809/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0441 - val_loss: 266.8615\n",
      "Epoch 810/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0436 - val_loss: 266.8606\n",
      "Epoch 811/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0435 - val_loss: 266.8640\n",
      "Epoch 812/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0474 - val_loss: 266.8596\n",
      "Epoch 813/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0450 - val_loss: 266.8666\n",
      "Epoch 814/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0441 - val_loss: 266.8624\n",
      "Epoch 815/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0428 - val_loss: 266.8624\n",
      "Epoch 816/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0429 - val_loss: 266.8605\n",
      "Epoch 817/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0434 - val_loss: 266.8554\n",
      "Epoch 818/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0431 - val_loss: 266.8572\n",
      "Epoch 819/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0425 - val_loss: 266.8592\n",
      "Epoch 820/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0427 - val_loss: 266.8624\n",
      "Epoch 821/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0432 - val_loss: 266.8608\n",
      "Epoch 822/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0440 - val_loss: 266.8638\n",
      "Epoch 823/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0437 - val_loss: 266.8655\n",
      "Epoch 824/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0430 - val_loss: 266.8650\n",
      "Epoch 825/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0430 - val_loss: 266.8649\n",
      "Epoch 826/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0433 - val_loss: 266.8632\n",
      "Epoch 827/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0436 - val_loss: 266.8624\n",
      "Epoch 828/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0426 - val_loss: 266.8623\n",
      "Epoch 829/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0432 - val_loss: 266.8586\n",
      "Epoch 830/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0432 - val_loss: 266.8612\n",
      "Epoch 831/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0429 - val_loss: 266.8622\n",
      "Epoch 832/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0436 - val_loss: 266.8635\n",
      "Epoch 833/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0423 - val_loss: 266.8597\n",
      "Epoch 834/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0431 - val_loss: 266.8585\n",
      "Epoch 835/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0443 - val_loss: 266.8610\n",
      "Epoch 836/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0441 - val_loss: 266.8613\n",
      "Epoch 837/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0428 - val_loss: 266.8612\n",
      "Epoch 838/6500\n",
      "27/27 [==============================] - 2s 77ms/step - loss: 260.0440 - val_loss: 266.8663\n",
      "Epoch 839/6500\n",
      "27/27 [==============================] - 2s 72ms/step - loss: 260.0435 - val_loss: 266.8640\n",
      "Epoch 840/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0437 - val_loss: 266.8612\n",
      "Epoch 841/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0428 - val_loss: 266.8620\n",
      "Epoch 842/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0432 - val_loss: 266.8641\n",
      "Epoch 843/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0429 - val_loss: 266.8615\n",
      "Epoch 844/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0436 - val_loss: 266.8602\n",
      "Epoch 845/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0435 - val_loss: 266.8602\n",
      "Epoch 846/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0432 - val_loss: 266.8601\n",
      "Epoch 847/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0473 - val_loss: 266.8600\n",
      "Epoch 848/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0429 - val_loss: 266.8608\n",
      "Epoch 849/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0437 - val_loss: 266.8588\n",
      "Epoch 850/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0449 - val_loss: 266.8688\n",
      "Epoch 851/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0434 - val_loss: 266.8632\n",
      "Epoch 852/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0441 - val_loss: 266.8625\n",
      "Epoch 853/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0437 - val_loss: 266.8655\n",
      "Epoch 854/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0436 - val_loss: 266.8622\n",
      "Epoch 855/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0443 - val_loss: 266.8617\n",
      "Epoch 856/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0427 - val_loss: 266.8615\n",
      "Epoch 857/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0432 - val_loss: 266.8610\n",
      "Epoch 858/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0427 - val_loss: 266.8607\n",
      "Epoch 859/6500\n",
      "27/27 [==============================] - 2s 55ms/step - loss: 260.0432 - val_loss: 266.8618\n",
      "Epoch 860/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0434 - val_loss: 266.8610\n",
      "Epoch 861/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0426 - val_loss: 266.8620\n",
      "Epoch 862/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0429 - val_loss: 266.8615\n",
      "Epoch 863/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0430 - val_loss: 266.8610\n",
      "Epoch 864/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0427 - val_loss: 266.8620\n",
      "Epoch 865/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0434 - val_loss: 266.8635\n",
      "Epoch 866/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0433 - val_loss: 266.8600\n",
      "Epoch 867/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0427 - val_loss: 266.8629\n",
      "Epoch 868/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0437 - val_loss: 266.8628\n",
      "Epoch 869/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0432 - val_loss: 266.8635\n",
      "Epoch 870/6500\n",
      "27/27 [==============================] - 2s 55ms/step - loss: 260.0421 - val_loss: 266.8601\n",
      "Epoch 871/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0423 - val_loss: 266.8604\n",
      "Epoch 872/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0428 - val_loss: 266.8570\n",
      "Epoch 873/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0434 - val_loss: 266.8613\n",
      "Epoch 874/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0427 - val_loss: 266.8604\n",
      "Epoch 875/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0428 - val_loss: 266.8629\n",
      "Epoch 876/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0426 - val_loss: 266.8605\n",
      "Epoch 877/6500\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 260.0428 - val_loss: 266.8620\n",
      "Epoch 878/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0429 - val_loss: 266.8587\n",
      "Epoch 879/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0438 - val_loss: 266.8641\n",
      "Epoch 880/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0421 - val_loss: 266.8634\n",
      "Epoch 881/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0432 - val_loss: 266.8600\n",
      "Epoch 882/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0433 - val_loss: 266.8644\n",
      "Epoch 883/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0441 - val_loss: 266.8605\n",
      "Epoch 884/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0418 - val_loss: 266.8658\n",
      "Epoch 885/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0441 - val_loss: 266.8604\n",
      "Epoch 886/6500\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 260.0434 - val_loss: 266.8672\n",
      "Epoch 887/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0428 - val_loss: 266.8652\n",
      "Epoch 888/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0439 - val_loss: 266.8611\n",
      "Epoch 889/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0427 - val_loss: 266.8675\n",
      "Epoch 890/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0423 - val_loss: 266.8635\n",
      "Epoch 891/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0431 - val_loss: 266.8630\n",
      "Epoch 892/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0424 - val_loss: 266.8585\n",
      "Epoch 893/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0435 - val_loss: 266.8617\n",
      "Epoch 894/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0432 - val_loss: 266.8620\n",
      "Epoch 895/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0431 - val_loss: 266.8560\n",
      "Epoch 896/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0420 - val_loss: 266.8628\n",
      "Epoch 897/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0434 - val_loss: 266.8634\n",
      "Epoch 898/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0431 - val_loss: 266.8670\n",
      "Epoch 899/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0422 - val_loss: 266.8604\n",
      "Epoch 900/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0429 - val_loss: 266.8613\n",
      "Epoch 901/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0422 - val_loss: 266.8608\n",
      "Epoch 902/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0426 - val_loss: 266.8603\n",
      "Epoch 903/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0425 - val_loss: 266.8613\n",
      "Epoch 904/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0442 - val_loss: 266.8591\n",
      "Epoch 905/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0426 - val_loss: 266.8601\n",
      "Epoch 906/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0423 - val_loss: 266.8623\n",
      "Epoch 907/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0423 - val_loss: 266.8619\n",
      "Epoch 908/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0441 - val_loss: 266.8632\n",
      "Epoch 909/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0419 - val_loss: 266.8635\n",
      "Epoch 910/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0427 - val_loss: 266.8610\n",
      "Epoch 911/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0423 - val_loss: 266.8602\n",
      "Epoch 912/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0424 - val_loss: 266.8607\n",
      "Epoch 913/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0425 - val_loss: 266.8629\n",
      "Epoch 914/6500\n",
      "27/27 [==============================] - 2s 62ms/step - loss: 260.0424 - val_loss: 266.8587\n",
      "Epoch 915/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0422 - val_loss: 266.8629\n",
      "Epoch 916/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0426 - val_loss: 266.8642\n",
      "Epoch 917/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0440 - val_loss: 266.8595\n",
      "Epoch 918/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0430 - val_loss: 266.8646\n",
      "Epoch 919/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0446 - val_loss: 266.8693\n",
      "Epoch 920/6500\n",
      "27/27 [==============================] - 2s 87ms/step - loss: 260.0430 - val_loss: 266.8577\n",
      "Epoch 921/6500\n",
      "27/27 [==============================] - 2s 61ms/step - loss: 260.0423 - val_loss: 266.8594\n",
      "Epoch 922/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0419 - val_loss: 266.8588\n",
      "Epoch 923/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0425 - val_loss: 266.8637\n",
      "Epoch 924/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0423 - val_loss: 266.8633\n",
      "Epoch 925/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0422 - val_loss: 266.8583\n",
      "Epoch 926/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 260.0429 - val_loss: 266.8593\n",
      "Epoch 927/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0423 - val_loss: 266.8614\n",
      "Epoch 928/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0424 - val_loss: 266.8609\n",
      "Epoch 929/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0421 - val_loss: 266.8610\n",
      "Epoch 930/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0425 - val_loss: 266.8593\n",
      "Epoch 931/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0421 - val_loss: 266.8619\n",
      "Epoch 932/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0423 - val_loss: 266.8597\n",
      "Epoch 933/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0431 - val_loss: 266.8574\n",
      "Epoch 934/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0442 - val_loss: 266.8651\n",
      "Epoch 935/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0421 - val_loss: 266.8626\n",
      "Epoch 936/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0432 - val_loss: 266.8639\n",
      "Epoch 937/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0432 - val_loss: 266.8617\n",
      "Epoch 938/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0427 - val_loss: 266.8612\n",
      "Epoch 939/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0431 - val_loss: 266.8653\n",
      "Epoch 940/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0438 - val_loss: 266.8541\n",
      "Epoch 941/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0432 - val_loss: 266.8589\n",
      "Epoch 942/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0432 - val_loss: 266.8670\n",
      "Epoch 943/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0424 - val_loss: 266.8663\n",
      "Epoch 944/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0427 - val_loss: 266.8640\n",
      "Epoch 945/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0420 - val_loss: 266.8655\n",
      "Epoch 946/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0423 - val_loss: 266.8639\n",
      "Epoch 947/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0415 - val_loss: 266.8660\n",
      "Epoch 948/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0428 - val_loss: 266.8652\n",
      "Epoch 949/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0429 - val_loss: 266.8609\n",
      "Epoch 950/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0437 - val_loss: 266.8657\n",
      "Epoch 951/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0426 - val_loss: 266.8612\n",
      "Epoch 952/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0417 - val_loss: 266.8631\n",
      "Epoch 953/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0414 - val_loss: 266.8636\n",
      "Epoch 954/6500\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 260.0437 - val_loss: 266.8607\n",
      "Epoch 955/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0424 - val_loss: 266.8643\n",
      "Epoch 956/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0422 - val_loss: 266.8605\n",
      "Epoch 957/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0423 - val_loss: 266.8663\n",
      "Epoch 958/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0427 - val_loss: 266.8618\n",
      "Epoch 959/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0419 - val_loss: 266.8639\n",
      "Epoch 960/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0421 - val_loss: 266.8660\n",
      "Epoch 961/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0438 - val_loss: 266.8625\n",
      "Epoch 962/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0441 - val_loss: 266.8622\n",
      "Epoch 963/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0421 - val_loss: 266.8606\n",
      "Epoch 964/6500\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 260.0442 - val_loss: 266.8631\n",
      "Epoch 965/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0422 - val_loss: 266.8593\n",
      "Epoch 966/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0424 - val_loss: 266.8599\n",
      "Epoch 967/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0425 - val_loss: 266.8622\n",
      "Epoch 968/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0423 - val_loss: 266.8656\n",
      "Epoch 969/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0421 - val_loss: 266.8623\n",
      "Epoch 970/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0420 - val_loss: 266.8632\n",
      "Epoch 971/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0429 - val_loss: 266.8669\n",
      "Epoch 972/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0429 - val_loss: 266.8562\n",
      "Epoch 973/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0434 - val_loss: 266.8653\n",
      "Epoch 974/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0424 - val_loss: 266.8644\n",
      "Epoch 975/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0423 - val_loss: 266.8570\n",
      "Epoch 976/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0420 - val_loss: 266.8580\n",
      "Epoch 977/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0433 - val_loss: 266.8613\n",
      "Epoch 978/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0417 - val_loss: 266.8601\n",
      "Epoch 979/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 260.0422 - val_loss: 266.8564\n",
      "Epoch 980/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0420 - val_loss: 266.8577\n",
      "Epoch 981/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0442 - val_loss: 266.8619\n",
      "Epoch 982/6500\n",
      "27/27 [==============================] - 2s 93ms/step - loss: 260.0420 - val_loss: 266.8593\n",
      "Epoch 983/6500\n",
      "27/27 [==============================] - 1s 56ms/step - loss: 260.0432 - val_loss: 266.8592\n",
      "Epoch 984/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0420 - val_loss: 266.8589\n",
      "Epoch 985/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0420 - val_loss: 266.8576\n",
      "Epoch 986/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0434 - val_loss: 266.8591\n",
      "Epoch 987/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0427 - val_loss: 266.8584\n",
      "Epoch 988/6500\n",
      "27/27 [==============================] - 2s 92ms/step - loss: 260.0421 - val_loss: 266.8618\n",
      "Epoch 989/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 2s 56ms/step - loss: 260.0419 - val_loss: 266.8635\n",
      "Epoch 990/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0418 - val_loss: 266.8587\n",
      "Epoch 991/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0423 - val_loss: 266.8609\n",
      "Epoch 992/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0429 - val_loss: 266.8631\n",
      "Epoch 993/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0425 - val_loss: 266.8590\n",
      "Epoch 994/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 260.0439 - val_loss: 266.8622\n",
      "Epoch 995/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0424 - val_loss: 266.8589\n",
      "Epoch 996/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0427 - val_loss: 266.8572\n",
      "Epoch 997/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0409 - val_loss: 266.8626\n",
      "Epoch 998/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0421 - val_loss: 266.8594\n",
      "Epoch 999/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0414 - val_loss: 266.8619\n",
      "Epoch 1000/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0420 - val_loss: 266.8651\n",
      "Epoch 1001/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0422 - val_loss: 266.8640\n",
      "Epoch 1002/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0431 - val_loss: 266.8625\n",
      "Epoch 1003/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0425 - val_loss: 266.8549\n",
      "Epoch 1004/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0423 - val_loss: 266.8658\n",
      "Epoch 1005/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0422 - val_loss: 266.8581\n",
      "Epoch 1006/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0417 - val_loss: 266.8663\n",
      "Epoch 1007/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0418 - val_loss: 266.8626\n",
      "Epoch 1008/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0419 - val_loss: 266.8641\n",
      "Epoch 1009/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0423 - val_loss: 266.8622\n",
      "Epoch 1010/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0414 - val_loss: 266.8620\n",
      "Epoch 1011/6500\n",
      "27/27 [==============================] - 2s 94ms/step - loss: 260.0424 - val_loss: 266.8650\n",
      "Epoch 1012/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0414 - val_loss: 266.8600\n",
      "Epoch 1013/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0423 - val_loss: 266.8636\n",
      "Epoch 1014/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0438 - val_loss: 266.8582\n",
      "Epoch 1015/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0412 - val_loss: 266.8579\n",
      "Epoch 1016/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0424 - val_loss: 266.8574\n",
      "Epoch 1017/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0412 - val_loss: 266.8599\n",
      "Epoch 1018/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0437 - val_loss: 266.8586\n",
      "Epoch 1019/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0421 - val_loss: 266.8625\n",
      "Epoch 1020/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0424 - val_loss: 266.8638\n",
      "Epoch 1021/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0433 - val_loss: 266.8612\n",
      "Epoch 1022/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0426 - val_loss: 266.8622\n",
      "Epoch 1023/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0419 - val_loss: 266.8616\n",
      "Epoch 1024/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0423 - val_loss: 266.8626\n",
      "Epoch 1025/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0410 - val_loss: 266.8591\n",
      "Epoch 1026/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0414 - val_loss: 266.8592\n",
      "Epoch 1027/6500\n",
      "27/27 [==============================] - 1s 50ms/step - loss: 260.0418 - val_loss: 266.8583\n",
      "Epoch 1028/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0419 - val_loss: 266.8651\n",
      "Epoch 1029/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0421 - val_loss: 266.8611\n",
      "Epoch 1030/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0419 - val_loss: 266.8617\n",
      "Epoch 1031/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0412 - val_loss: 266.8579\n",
      "Epoch 1032/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0423 - val_loss: 266.8612\n",
      "Epoch 1033/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0419 - val_loss: 266.8565\n",
      "Epoch 1034/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0421 - val_loss: 266.8598\n",
      "Epoch 1035/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0417 - val_loss: 266.8608\n",
      "Epoch 1036/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0425 - val_loss: 266.8576\n",
      "Epoch 1037/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0436 - val_loss: 266.8653\n",
      "Epoch 1038/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0408 - val_loss: 266.8574\n",
      "Epoch 1039/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0414 - val_loss: 266.8580\n",
      "Epoch 1040/6500\n",
      "27/27 [==============================] - 3s 96ms/step - loss: 260.0423 - val_loss: 266.8621\n",
      "Epoch 1041/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0410 - val_loss: 266.8610\n",
      "Epoch 1042/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0424 - val_loss: 266.8651\n",
      "Epoch 1043/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0419 - val_loss: 266.8586\n",
      "Epoch 1044/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0422 - val_loss: 266.8593\n",
      "Epoch 1045/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0410 - val_loss: 266.8639\n",
      "Epoch 1046/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0426 - val_loss: 266.8623\n",
      "Epoch 1047/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0421 - val_loss: 266.8605\n",
      "Epoch 1048/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0423 - val_loss: 266.8590\n",
      "Epoch 1049/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0414 - val_loss: 266.8613\n",
      "Epoch 1050/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0410 - val_loss: 266.8594\n",
      "Epoch 1051/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0419 - val_loss: 266.8582\n",
      "Epoch 1052/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0416 - val_loss: 266.8628\n",
      "Epoch 1053/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0413 - val_loss: 266.8608\n",
      "Epoch 1054/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0412 - val_loss: 266.8569\n",
      "Epoch 1055/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0418 - val_loss: 266.8557\n",
      "Epoch 1056/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0426 - val_loss: 266.8626\n",
      "Epoch 1057/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0430 - val_loss: 266.8648\n",
      "Epoch 1058/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0409 - val_loss: 266.8613\n",
      "Epoch 1059/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0414 - val_loss: 266.8611\n",
      "Epoch 1060/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0415 - val_loss: 266.8571\n",
      "Epoch 1061/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0419 - val_loss: 266.8590\n",
      "Epoch 1062/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0417 - val_loss: 266.8592\n",
      "Epoch 1063/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0440 - val_loss: 266.8571\n",
      "Epoch 1064/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0415 - val_loss: 266.8611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1065/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0419 - val_loss: 266.8630\n",
      "Epoch 1066/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0412 - val_loss: 266.8602\n",
      "Epoch 1067/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0414 - val_loss: 266.8638\n",
      "Epoch 1068/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0410 - val_loss: 266.8569\n",
      "Epoch 1069/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0415 - val_loss: 266.8619\n",
      "Epoch 1070/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0419 - val_loss: 266.8579\n",
      "Epoch 1071/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0412 - val_loss: 266.8612\n",
      "Epoch 1072/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0414 - val_loss: 266.8615\n",
      "Epoch 1073/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0422 - val_loss: 266.8622\n",
      "Epoch 1074/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0411 - val_loss: 266.8607\n",
      "Epoch 1075/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0422 - val_loss: 266.8585\n",
      "Epoch 1076/6500\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 260.0416 - val_loss: 266.8615\n",
      "Epoch 1077/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0418 - val_loss: 266.8585\n",
      "Epoch 1078/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0415 - val_loss: 266.8592\n",
      "Epoch 1079/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0410 - val_loss: 266.8590\n",
      "Epoch 1080/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0410 - val_loss: 266.8616\n",
      "Epoch 1081/6500\n",
      "27/27 [==============================] - 3s 93ms/step - loss: 260.0408 - val_loss: 266.8647\n",
      "Epoch 1082/6500\n",
      "27/27 [==============================] - 1s 53ms/step - loss: 260.0414 - val_loss: 266.8599\n",
      "Epoch 1083/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0414 - val_loss: 266.8584\n",
      "Epoch 1084/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0409 - val_loss: 266.8592\n",
      "Epoch 1085/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0411 - val_loss: 266.8596\n",
      "Epoch 1086/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0414 - val_loss: 266.8642\n",
      "Epoch 1087/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0412 - val_loss: 266.8639\n",
      "Epoch 1088/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0419 - val_loss: 266.8621\n",
      "Epoch 1089/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0409 - val_loss: 266.8612\n",
      "Epoch 1090/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0417 - val_loss: 266.8619\n",
      "Epoch 1091/6500\n",
      "27/27 [==============================] - 3s 94ms/step - loss: 260.0407 - val_loss: 266.8625\n",
      "Epoch 1092/6500\n",
      "27/27 [==============================] - 1s 54ms/step - loss: 260.0412 - val_loss: 266.8644\n",
      "Epoch 1093/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0408 - val_loss: 266.8604\n",
      "Epoch 1094/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0410 - val_loss: 266.8610\n",
      "Epoch 1095/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0417 - val_loss: 266.8596\n",
      "Epoch 1096/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0425 - val_loss: 266.8588\n",
      "Epoch 1097/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0406 - val_loss: 266.8613\n",
      "Epoch 1098/6500\n",
      "27/27 [==============================] - 3s 119ms/step - loss: 260.0413 - val_loss: 266.8580\n",
      "Epoch 1099/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0405 - val_loss: 266.8613\n",
      "Epoch 1100/6500\n",
      "27/27 [==============================] - 2s 67ms/step - loss: 260.0406 - val_loss: 266.8597\n",
      "Epoch 1101/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 260.0408 - val_loss: 266.8578\n",
      "Epoch 1102/6500\n",
      "27/27 [==============================] - 3s 106ms/step - loss: 260.0415 - val_loss: 266.8568\n",
      "Epoch 1103/6500\n",
      "27/27 [==============================] - 3s 108ms/step - loss: 260.0413 - val_loss: 266.8610\n",
      "Epoch 1104/6500\n",
      "27/27 [==============================] - 3s 105ms/step - loss: 260.0407 - val_loss: 266.8603\n",
      "Epoch 1105/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0417 - val_loss: 266.8582\n",
      "Epoch 1106/6500\n",
      "27/27 [==============================] - 3s 103ms/step - loss: 260.0404 - val_loss: 266.8654\n",
      "Epoch 1107/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0407 - val_loss: 266.8622\n",
      "Epoch 1108/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0410 - val_loss: 266.8665\n",
      "Epoch 1109/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0410 - val_loss: 266.8642\n",
      "Epoch 1110/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0402 - val_loss: 266.8596\n",
      "Epoch 1111/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0409 - val_loss: 266.8605\n",
      "Epoch 1112/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0410 - val_loss: 266.8614\n",
      "Epoch 1113/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0414 - val_loss: 266.8581\n",
      "Epoch 1114/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0416 - val_loss: 266.8576\n",
      "Epoch 1115/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0411 - val_loss: 266.8586\n",
      "Epoch 1116/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0427 - val_loss: 266.8603\n",
      "Epoch 1117/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0427 - val_loss: 266.8670\n",
      "Epoch 1118/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0403 - val_loss: 266.8616\n",
      "Epoch 1119/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0407 - val_loss: 266.8592\n",
      "Epoch 1120/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0417 - val_loss: 266.8583\n",
      "Epoch 1121/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0435 - val_loss: 266.8604\n",
      "Epoch 1122/6500\n",
      "27/27 [==============================] - 2s 56ms/step - loss: 260.0408 - val_loss: 266.8538\n",
      "Epoch 1123/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0414 - val_loss: 266.8562\n",
      "Epoch 1124/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0419 - val_loss: 266.8588\n",
      "Epoch 1125/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0417 - val_loss: 266.8639\n",
      "Epoch 1126/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0407 - val_loss: 266.8624\n",
      "Epoch 1127/6500\n",
      "27/27 [==============================] - 2s 90ms/step - loss: 260.0408 - val_loss: 266.8650\n",
      "Epoch 1128/6500\n",
      "27/27 [==============================] - 2s 59ms/step - loss: 260.0415 - val_loss: 266.8610\n",
      "Epoch 1129/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0406 - val_loss: 266.8627\n",
      "Epoch 1130/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0418 - val_loss: 266.8604\n",
      "Epoch 1131/6500\n",
      "27/27 [==============================] - 3s 102ms/step - loss: 260.0405 - val_loss: 266.8651\n",
      "Epoch 1132/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0411 - val_loss: 266.8631\n",
      "Epoch 1133/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0416 - val_loss: 266.8644\n",
      "Epoch 1134/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0406 - val_loss: 266.8639\n",
      "Epoch 1135/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0401 - val_loss: 266.8604\n",
      "Epoch 1136/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0408 - val_loss: 266.8614\n",
      "Epoch 1137/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0403 - val_loss: 266.8601\n",
      "Epoch 1138/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0408 - val_loss: 266.8593\n",
      "Epoch 1139/6500\n",
      "27/27 [==============================] - 1s 55ms/step - loss: 260.0414 - val_loss: 266.8578\n",
      "Epoch 1140/6500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0408 - val_loss: 266.8600\n",
      "Epoch 1141/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0415 - val_loss: 266.8669\n",
      "Epoch 1142/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0424 - val_loss: 266.8561\n",
      "Epoch 1143/6500\n",
      "27/27 [==============================] - 3s 100ms/step - loss: 260.0402 - val_loss: 266.8594\n",
      "Epoch 1144/6500\n",
      "27/27 [==============================] - 1s 51ms/step - loss: 260.0408 - val_loss: 266.8582\n",
      "Epoch 1145/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0417 - val_loss: 266.8553\n",
      "Epoch 1146/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0414 - val_loss: 266.8572\n",
      "Epoch 1147/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0407 - val_loss: 266.8595\n",
      "Epoch 1148/6500\n",
      "27/27 [==============================] - 3s 95ms/step - loss: 260.0423 - val_loss: 266.8604\n",
      "Epoch 1149/6500\n",
      "27/27 [==============================] - 1s 52ms/step - loss: 260.0409 - val_loss: 266.8602\n",
      "Epoch 1150/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0444 - val_loss: 266.8582\n",
      "Epoch 1151/6500\n",
      "27/27 [==============================] - 3s 98ms/step - loss: 260.0418 - val_loss: 266.8611\n",
      "Epoch 1152/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0410 - val_loss: 266.8598\n",
      "Epoch 1153/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0409 - val_loss: 266.8642\n",
      "Epoch 1154/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0410 - val_loss: 266.8607\n",
      "Epoch 1155/6500\n",
      "27/27 [==============================] - 1s 48ms/step - loss: 260.0414 - val_loss: 266.8625\n",
      "Epoch 1156/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0414 - val_loss: 266.8584\n",
      "Epoch 1157/6500\n",
      "27/27 [==============================] - 3s 104ms/step - loss: 260.0412 - val_loss: 266.8540\n",
      "Epoch 1158/6500\n",
      "27/27 [==============================] - 3s 101ms/step - loss: 260.0403 - val_loss: 266.8574\n",
      "Epoch 1159/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0406 - val_loss: 266.8659\n",
      "Epoch 1160/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0407 - val_loss: 266.8645\n",
      "Epoch 1161/6500\n",
      "27/27 [==============================] - 1s 49ms/step - loss: 260.0407 - val_loss: 266.8637\n",
      "Epoch 1162/6500\n",
      "27/27 [==============================] - 3s 99ms/step - loss: 260.0406 - val_loss: 266.8611\n",
      "Epoch 1163/6500\n",
      "27/27 [==============================] - 3s 97ms/step - loss: 260.0405 - val_loss: 266.8606\n",
      "Epoch 1164/6500\n",
      "19/27 [====================>.........] - ETA: 0s - loss: 259.6083"
     ]
    }
   ],
   "source": [
    "S1_r2, S1_rmse = train_eval(subject = \"01\", load_best=False, lr=0.001, eval_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "x68StdwXB_G5",
    "outputId": "e61ec846-556c-4da3-9588-54de3049ae78"
   },
   "outputs": [],
   "source": [
    "S1_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "KveKOwbaGl3O",
    "outputId": "4c4f85d9-2f38-4314-85c1-7125591ec5e6"
   },
   "outputs": [],
   "source": [
    "S1_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF_Individual_LSTM_github.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
